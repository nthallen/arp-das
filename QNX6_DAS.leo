<?xml version="1.0" encoding="utf-8"?>
<?xml-stylesheet ekr_test?>
<leo_file>
<leo_header file_format="2" tnodes="0" max_tnode_index="0" clone_windows="0"/>
<globals body_outline_ratio="0.301857585139">
	<global_window_position top="10" left="10" height="646" width="901"/>
	<global_log_window_position top="0" left="0" height="0" width="0"/>
</globals>
<preferences/>
<find_panel_settings/>
<vnodes>
<v t="ntallen.20070319130904" a="E"><vh>QNX6 Data Acquisition Architecture</vh>
<v t="ntallen.20070815151915" a="E"><vh>Status</vh>
<v t="ntallen.20080729145409"><vh>Overview</vh></v>
<v t="ntallen.20071127160602" a="E"><vh>OS Install</vh>
<v t="ntallen.20071127160602.1"><vh>Save</vh></v>
<v t="ntallen.20071204104659"><vh>Install</vh></v>
<v t="ntallen.20080702140151"><vh>Update to Trinity 2M7 Build</vh></v>
</v>
<v t="ntallen.20070815151915.1"><vh>Command</vh></v>
<v t="ntallen.20080516115802"><vh>memo</vh></v>
<v t="ntallen.20070815151915.2"><vh>Data</vh>
<v t="ntallen.20080715165457"><vh>tmc Changes</vh></v>
<v t="ntallen.20080716230618"><vh>Timestamp issue</vh></v>
<v t="ntallen.20080724120806"><vh>To Cache or not to Cache</vh></v>
<v t="ntallen.20080724120806.1" a="E"><vh>TM Receive</vh>
<v t="ntallen.20080724120806.2"><vh>Client library</vh></v>
<v t="ntallen.20080724120806.3"><vh>Collection Side</vh></v>
</v>
</v>
<v t="ntallen.20080627131220"><vh>Resources</vh>
<v t="ntallen.20080627131220.1"><vh>QFC</vh></v>
<v t="ntallen.20080627131220.2"><vh>Subversion and Eclipse</vh></v>
<v t="ntallen.20080627131220.3"><vh>doxygen</vh></v>
<v t="ntallen.20080627131220.4"><vh>pkgsrc</vh></v>
</v>
</v>
<v t="ntallen.20070815151915.3"><vh>Lessons</vh></v>
<v t="ntallen.20070409132623"><vh>PR</vh>
<v t="ntallen.20070409133739" a="E"><vh>Operation</vh>
<v t="ntallen.20070409133739.1"><vh>Configurations</vh>
<v t="ntallen.20070409132623.1"><vh>Full Up with GSE</vh></v>
<v t="ntallen.20070409132623.2"><vh>Flight Mode</vh></v>
<v t="ntallen.20070409132623.3"><vh>Playback</vh></v>
<v t="ntallen.20070409132623.4"><vh>Extraction</vh></v>
<v t="ntallen.20070409132623.5"><vh>Remote GSE</vh></v>
</v>
<v t="ntallen.20070409133739.2" a="E"><vh>Display Options</vh>
<v t="ntallen.20070409132623.6"><vh>Data</vh></v>
<v t="ntallen.20070409132623.7"><vh>Command</vh></v>
</v>
<v t="ntallen.20070409132623.8" a="E"><vh>Applications</vh>
<v t="ntallen.20070409132623.9"><vh>Memo</vh></v>
</v>
</v>
<v t="ntallen.20070409133739.3"><vh>Implementation</vh></v>
</v>
<v t="ntallen.20070413134915"><vh>QNX Development Issues</vh>
<v t="ntallen.20070425144317"><vh>Handling more than one executable per project</vh></v>
<v t="ntallen.20070413134915.1"><vh>Development Strategy</vh>
<v t="ntallen.20070425144317.1" a="E"><vh>cmdgen</vh>
<v t="ntallen.20070430134037"><vh>QNX4</vh></v>
</v>
<v t="ntallen.20070502121159"><vh>Names and Devices</vh></v>
<v t="ntallen.20070425144317.4"><vh>nortlib</vh></v>
<v t="ntallen.20070425144317.2"><vh>tmlib</vh></v>
<v t="ntallen.20070425144317.3"><vh>tmphlib</vh></v>
</v>
</v>
<v t="ntallen.20070502121159.1" a="E"><vh>Implementation</vh>
<v t="ntallen.20070320121924"><vh>cmdgen</vh>
<v t="ntallen.20070501165557"><vh>Done</vh>
<v t="ntallen.20070411152334" a="E"><vh>Add Interface Definitions</vh>
<v t="ntallen.20070404111542"><vh>Initialization</vh></v>
</v>
<v t="ntallen.20070501165557.1"><vh>Figure out appropriate library flag</vh></v>
<v t="ntallen.20070502121159.2" a="E"><vh>Syntax and version checking</vh>
<v t="ntallen.20070502121159.3"><vh>cis must produce syntax error messages</vh></v>
<v t="ntallen.20070502121159.4"><vh>cic must handle version test differently</vh></v>
</v>
<v t="ntallen.20070404165230.1"><vh>Handle Quit</vh></v>
<v t="ntallen.20070501165557.2"><vh>Fix up the experiment path correctly in cis.c</vh></v>
<v t="ntallen.20070508171951"><vh>cmdgen: cis_interface needs to be bracketed by #ifdef SERVER</vh></v>
<v t="ntallen.20070508171951.1"><vh>cmdgen: cmdgen.skel needs main() changes for PHOTON</vh></v>
<v t="ntallen.20070501165557.3"><vh>Tweak cmdgen.skel</vh></v>
<v t="ntallen.20070501165557.4"><vh>Write a photon command client</vh></v>
<v t="ntallen.20070508171951.3"><vh>cmdgen: cmdgen.skel needs to be distributed</vh></v>
<v t="ntallen.20070509151554"><vh>Move oui libary to $(datadir)/oui</vh></v>
<v t="ntallen.20070508171951.4"><vh>cmdgen: cmdgen.skel atexit() needs to be investigated</vh></v>
<v t="ntallen.20070509151554.1"><vh>cmdgen: cmdgen.skel SERVER DISPLAY_EOL</vh></v>
<v t="ntallen.20070508171951.5"><vh>Handle quit and exit in cmdclient</vh></v>
<v t="ntallen.20070509151554.2"><vh>Move cmdclient.c into tmphlib</vh></v>
<v t="ntallen.20070502121159.5"><vh>Memo interface can wait</vh></v>
<v t="ntallen.20070509151554.3"><vh>Add default .cmd files as appropriate</vh></v>
</v>
<v t="ntallen.20070508171951.2"><vh>Todo</vh>
<v t="ntallen.20070508171951.6"><vh>Draw polygon</vh></v>
<v t="ntallen.20070508171951.7"><vh>Get a cursor in cmd_text somehow</vh></v>
</v>
</v>
<v t="ntallen.20070509151554.4"><vh>appgen</vh>
<v t="ntallen.20070509151554.5"><vh>command server</vh></v>
</v>
<v t="ntallen.20080516115802.1"><vh>memo</vh></v>
</v>
<v t="ntallen.20070502121159.6" a="E"><vh>Design</vh>
<v t="ntallen.20070319130904.1"><vh>Data</vh>
<v t="ntallen.20070524163205" a="E"><vh>Data Issues</vh>
<v t="ntallen.20070524163205.1" a="E"><vh>What is the difference between the telemetry stream and the TM stream as returned from TMbfr?</vh>
<v t="ntallen.20070524163205.2"><vh>TM has no timestamps</vh></v>
<v t="ntallen.20070524163205.3"><vh>Does not include TM info struct or identifiers</vh></v>
</v>
<v t="ntallen.20070524163205.4"><vh>What form should Inetin/Inetout use?</vh></v>
<v t="ntallen.20080708155309"><vh>What are the optimized data formats that TMbfr supports?</vh>
<v t="ntallen.20080708155309.1"><vh>T1 full minor frames</vh></v>
<v t="ntallen.20080708155309.2"><vh>T2 full rows with header</vh></v>
<v t="ntallen.20080708155309.3"><vh>T3 optimized rows with header</vh></v>
<v t="ntallen.20080708155309.4"><vh>T4: T3 with chksum word</vh></v>
</v>
<v t="ntallen.20070524163205.5"><vh>What form should lgr/rdr use?</vh></v>
<v t="ntallen.20070524163205.6"><vh>What about other DGs? Collection?</vh></v>
<v t="ntallen.20070524163205.7"><vh>What sort of data transformations should TMbfr perform?</vh></v>
<v t="ntallen.20070524163205.9"><vh>TMbfr Client Options</vh>
<v t="ntallen.20070524163205.11"><vh>Incomplete Data</vh></v>
</v>
<v t="ntallen.20080715165457"><vh>tmc Changes</vh></v>
</v>
<v t="ntallen.20070319130904.2"><vh>TMbfr</vh>
<v t="ntallen.20070524163205.8" a="E"><vh>TMbfr Operation</vh>
<v t="ntallen.20080516131227"><vh>TMbfr Write Modes: O_NONBLOCK</vh></v>
<v t="ntallen.20080516131227.1"><vh>TMbfr Read Modes: DCo, DCf</vh></v>
<v t="ntallen.20070525114357"><vh>Register Names</vh></v>
<v t="ntallen.20070525114357.1"><vh>Delay allocating buffers</vh></v>
<v t="ntallen.20070525114357.2"><vh>DG initialization</vh></v>
<v t="ntallen.20070525114357.3"><vh>Store incoming data in circular queue</vh></v>
<v t="ntallen.20070525114357.4" a="E"><vh>Store metadata in linked list</vh>
<v t="ntallen.20070706110550"><vh>How to track reader progress</vh></v>
</v>
<v t="ntallen.20070525114357.5"><vh>Store TimeStamps in linked list</vh></v>
<v t="ntallen.20070529132018"><vh>Extend Attribute Structure</vh></v>
<v t="ntallen.20070529132018.1"><vh>Provide iofunc_open_handler for DG</vh></v>
<v t="ntallen.20070525114357.6" a="E"><vh>Store context in each OCB</vh>
<v t="ntallen.20070525132754"><vh>Partial frames</vh></v>
</v>
<v t="ntallen.20070529132018.2" a="E"><vh>io_write</vh>
<v t="ntallen.20070531163245" a="E"><vh>States</vh>
<v t="ntallen.20070529133623"><vh>Partial Header</vh></v>
<v t="ntallen.20070531162708"><vh>TM_Info</vh></v>
<v t="ntallen.20070529133623.1"><vh>Partial Data</vh></v>
</v>
<v t="ntallen.20070611133034"><vh>Data Handling</vh>
<v t="ntallen.20070612165620"><vh>States</vh></v>
<v t="ntallen.20080708165645"><vh>Conversions</vh></v>
<v t="ntallen.20070611133034.1"><vh>T1-&gt;T1</vh></v>
<v t="ntallen.20070611133034.2"><vh>T1-&gt;T2</vh></v>
<v t="ntallen.20070611133034.3"><vh>T1-&gt;T3</vh></v>
<v t="ntallen.20070611133034.4"><vh>T2-&gt;T1 x</vh></v>
<v t="ntallen.20070611133034.5"><vh>T2-&gt;T2</vh></v>
<v t="ntallen.20070611133034.6"><vh>T2-&gt;T3 x</vh></v>
<v t="ntallen.20070611133034.7"><vh>T3-&gt;T1 x</vh></v>
<v t="ntallen.20070611133034.8"><vh>T3-&gt;T2 x</vh></v>
<v t="ntallen.20070611133034.9"><vh>T3-&gt;T3</vh></v>
<v t="ntallen.20070612220750"><vh>Scratch</vh></v>
</v>
</v>
<v t="ntallen.20070531154309" a="E"><vh>io_read</vh>
<v t="ntallen.20070531163245.1" a="E"><vh>States</vh>
<v t="ntallen.20070531163245.2"><vh>Partial Header</vh></v>
<v t="ntallen.20070531163245.3"><vh>TM_Info</vh></v>
<v t="ntallen.20070531163245.4"><vh>Partial Data</vh></v>
</v>
</v>
<v t="ntallen.20070601102213"><vh>Commandability</vh></v>
</v>
<v t="ntallen.20070612165620.1"><vh>TMbfr Testing</vh></v>
</v>
<v t="ntallen.20070319130904.3"><vh>Data Generators</vh>
<v t="ntallen.20080516131227"><vh>TMbfr Write Modes: O_NONBLOCK</vh></v>
<v t="ntallen.20070817133522.5"><vh>DG API and design issues</vh>
<v t="ntallen.20080624104326"><vh>Interfaces</vh>
<v t="ntallen.20080625152707"><vh>Command Interfaces</vh></v>
<v t="ntallen.20080624104326.1" a="E"><vh>Driver Interface</vh>
<v t="ntallen.20080624104326.2"><vh>Driver Class</vh></v>
</v>
<v t="ntallen.20080624104326.3" a="E"><vh>Driver Synchronization</vh>
<v t="ntallen.20080624104326.4"><vh>Blocking writes</vh></v>
<v t="ntallen.20080624104326.5"><vh>Non-blocking writes and ionotify</vh></v>
</v>
</v>
<v t="ntallen.20080707135523" a="E"><vh>Main</vh>
<v t="ntallen.20080707135523.1"><vh>Read Thread</vh></v>
<v t="ntallen.20080708133047"><vh>Write Thread</vh></v>
</v>
<v t="ntallen.20070823131008"><vh>data_queue (DQ)</vh>
<v t="ntallen.20080710162929"><vh>DQ hierarchy</vh>
<v t="ntallen.20080710162929.1"><vh>Commands</vh></v>
<v t="ntallen.20080710162929.2"><vh>Collection strategy</vh></v>
<v t="ntallen.20080908205900" a="E"><vh>rdr (or general extraction) Strategy</vh>
<v t="ntallen.20080909114112"><vh>Control Thread</vh></v>
<v t="ntallen.20080710162929.3"><vh>Output Thread</vh></v>
<v t="ntallen.20080909114112.1"><vh>Input Thread</vh></v>
</v>
</v>
<v t="ntallen.20080708165645.1"><vh>Will DQ provide type translation?</vh></v>
<v t="ntallen.20080623133120"><vh>DQ Semaphore</vh></v>
<v t="ntallen.20070823131008.1" a="E"><vh>Writer operations</vh>
<v t="ntallen.20080709115758"><vh>Initialization</vh></v>
<v t="ntallen.20070823131008.2"><vh>allocate_rows(n_rows_max)</vh></v>
<v t="ntallen.20070823131008.3"><vh>commit_rows(MFCtr, row_start, n_rows)</vh></v>
<v t="ntallen.20070823131008.4"><vh>commit_tstamp(MFCtr, time)</vh></v>
</v>
<v t="ntallen.20070823131008.5" a="E"><vh>Reader operations</vh>
<v t="ntallen.20070823131008.6"><vh>transmit_rows(n_rows)</vh></v>
</v>
</v>
<v t="ntallen.20070820135203"><vh>Collection</vh></v>
<v t="ntallen.20070822162630"><vh>rdr</vh></v>
<v t="ntallen.20070822162630.1"><vh>Inetin</vh></v>
<v t="ntallen.20070820135203.1"><vh>Everything else</vh></v>
</v>
<v t="ntallen.20070319130904.4"><vh>Collection</vh>
<v t="ntallen.20070404221945"><vh>Define data interfaces</vh></v>
</v>
<v t="ntallen.20070319130904.5"><vh>rdr</vh></v>
<v t="ntallen.20070319130904.6"><vh>Inetin</vh></v>
<v t="ntallen.20080516132543"><vh>TMRelay</vh></v>
</v>
<v t="ntallen.20070319130904.7"><vh>Data Clients</vh>
<v t="ntallen.20080519132626"><vh>DC API</vh></v>
<v t="ntallen.20080516131227.1"><vh>TMbfr Read Modes: DCo, DCf</vh></v>
<v t="ntallen.20070319130904.8"><vh>lgr</vh></v>
<v t="ntallen.20070319130904.9"><vh>display</vh></v>
<v t="ntallen.20070319130904.10"><vh>extractions</vh></v>
<v t="ntallen.20070319130904.11"><vh>algorithms</vh></v>
</v>
<v t="ntallen.20070404221945.1"><vh>TMC rework</vh></v>
<v t="ntallen.20070404221945.2"><vh>SNAFU/ssp library</vh></v>
</v>
<v t="ntallen.20070319130904.12"><vh>Command</vh>
<v t="ntallen.20070320110353"><vh>Command Server</vh>
<v t="ntallen.20070320135407"><vh>Reader Interface Definition</vh>
<v t="ntallen.20070320135407.1"><vh>Node Name</vh></v>
<v t="ntallen.20070320135407.2"><vh>Client Message Definition</vh>
<v t="ntallen.20070320135407.4"><vh>Message contents</vh></v>
<v t="ntallen.20070320135407.5"><vh>Queue Length</vh></v>
</v>
<v t="ntallen.20070320140803" a="E"><vh>Operation</vh>
<v t="ntallen.20070330134656.1" a="E"><vh>Command Type</vh></v>
</v>
<v t="ntallen.20070320140803.1"><vh>Errors</vh>
<v t="ntallen.20070320140803.2"><vh>Out of Memory</vh></v>
<v t="ntallen.20070320140803.3"><vh>No Readers</vh></v>
<v t="ntallen.20070320140803.4"><vh>Missed Command</vh></v>
</v>
</v>
<v t="ntallen.20070404111542.1"><vh>Write Interface Definition</vh>
<v t="ntallen.20070404111542.2"><vh>How will syntax testing work?</vh></v>
</v>
<v t="ntallen.20070320150841"><vh>Development Plan</vh>
<v t="ntallen.20070403140218"><vh>resmgr_attach()</vh>
<v t="ntallen.20070403140218.1"><vh>dispatch_t *dpp</vh></v>
<v t="ntallen.20070403140218.2"><vh>resmgr_attr_t resmgr_attr</vh></v>
<v t="ntallen.20070403140218.3"><vh>path</vh></v>
<v t="ntallen.20070403140218.4"><vh>IOFUNC_ATTR_T handle</vh>
<v t="ntallen.20070403140218.5"><vh>iofunc_mount_t mountpoint</vh></v>
</v>
</v>
<v t="ntallen.20070330134656"><vh>Define data structures for queuing command output</vh>
<v t="ntallen.20070330134656.1"><vh>Command Type</vh></v>
</v>
<v t="ntallen.20070404165230"><vh>Support SELECT</vh></v>
<v t="ntallen.20070404165230.1"><vh>Handle Quit</vh></v>
<v t="ntallen.20070320150841.4"><vh>Incorporate cmdgen</vh></v>
<v t="ntallen.20070404165230.2"><vh>Support Signals</vh></v>
</v>
</v>
<v t="ntallen.20070320150524.1"><vh>Command Sources</vh>
<v t="ntallen.20070320150524.2"><vh>Keyboard</vh></v>
<v t="ntallen.20070320150524.3"><vh>Algorithm</vh></v>
</v>
<v t="ntallen.20070320150524.4"><vh>Command Receivers</vh>
<v t="ntallen.20070320150524.5"><vh>DG</vh></v>
<v t="ntallen.20070320150524.6"><vh>lgr</vh></v>
<v t="ntallen.20070320150524.7"><vh>TMbfr</vh></v>
<v t="ntallen.20070320150524.8"><vh>Indexer</vh></v>
<v t="ntallen.20070320150524.9"><vh>SCDC/DCCC</vh></v>
<v t="ntallen.20070322160353"><vh>Quit</vh></v>
</v>
</v>
<v t="ntallen.20070322130922"><vh>memo</vh>
<v t="ntallen.20070322160353.1"><vh>Message formatting probably takes place in the library</vh></v>
<v t="ntallen.20070322130922.1"><vh>Adopt /dev/huarp/exp/memo</vh></v>
<v t="ntallen.20070322130922.3"><vh>Write to log file, etc.</vh></v>
<v t="ntallen.20070330134656.3"><vh>Can eliminate ocb_funcs here</vh></v>
<v t="ntallen.20070322130922.2"><vh>Accept atomic writes from multiple sources</vh></v>
<v t="ntallen.20070322160353.2" a="E"><vh>Strategy for termination, communication with the command server</vh>
<v t="ntallen.20070322180349"><vh>Find out how to gracefully shut down a resource manager</vh></v>
<v t="ntallen.20070322160353.3"><vh>Avoiding Deadlock</vh></v>
<v t="ntallen.20070322160353.4"><vh>Terminate after at least one client has opened and all have closed</vh></v>
</v>
</v>
<v t="ntallen.20090202133816" a="E"><vh>Utilities</vh>
<v t="ntallen.20090202133816.1" a="E"><vh>mkdoit</vh>
<v t="ntallen.20090202133816.2"><vh>Dedicated Acquisition node</vh></v>
<v t="ntallen.20090202133816.3"><vh>Development node</vh></v>
</v>
</v>
</v>
<v t="ntallen.20070404221945.3" a="E"><vh>Graphics</vh>
<v t="ntallen.20090203160910" a="E"><vh>plot</vh>
<v t="ntallen.20090203160910.1" a="E"><vh>Object hierarchy</vh>
<v t="ntallen.20090203162108" a="E"><vh>Axes</vh>
<v t="ntallen.20090203160910.2"><vh>Axes scenarios</vh></v>
</v>
</v>
<v t="ntallen.20090203162108.1" a="TV"><vh>Photon Issues</vh></v>
</v>
</v>
<v t="ntallen.20070404221945.4" a="E"><vh>Drivers</vh>
<v t="ntallen.20070404221945.5"><vh>Subbus</vh></v>
<v t="ntallen.20070404221945.6"><vh>SCDC/DCCC</vh></v>
<v t="ntallen.20070404221945.7"><vh>Indexer</vh></v>
<v t="ntallen.20070404221945.8"><vh>Thompson?</vh></v>
<v t="ntallen.20070404221945.9"><vh>dacache</vh></v>
</v>
<v t="ntallen.20070323134835" a="E"><vh>Resmgr Notes</vh>
<v t="ntallen.20070323134835.1"><vh>resmgr_attach()</vh>
<v t="ntallen.20080625171218" a="E"><vh>Meta</vh>
<v t="ntallen.20080630113952"><vh>DG_dispatch</vh></v>
<v t="ntallen.20080626163820"><vh>device semantics</vh></v>
</v>
<v t="ntallen.20070323134835.2"><vh>dispatch_t *dpp</vh></v>
<v t="ntallen.20070323134835.3"><vh>resmgr_attr_t resmgr_attr</vh></v>
<v t="ntallen.20070323134835.4"><vh>path</vh></v>
<v t="ntallen.20070323134835.5" a="E"><vh>iofunc_attr_t handle</vh>
<v t="ntallen.20070323134835.6"><vh>iofunc_mount_t mountpoint</vh></v>
</v>
</v>
<v t="ntallen.20070330134656.4"><vh>OCB</vh></v>
<v t="ntallen.20070330134656.5"><vh>Strategy for multiple readers</vh></v>
</v>
<v t="ntallen.20070817133522" a="E"><vh>Documentation</vh>
<v t="ntallen.20070817133522.1" a="E"><vh>QNX4</vh>
<v t="ntallen.20070817133522.2"><vh>DG</vh></v>
</v>
<v t="ntallen.20070817133522.3"><vh>QNX6</vh>
<v t="ntallen.20080716155154"><vh>DataQueue.h</vh>
<v t="ntallen.20080716155154.1"><vh>DG.h</vh>
<v t="ntallen.20080716155154.2"><vh>Collector.h</vh></v>
<v t="ntallen.20080716155154.3"><vh>Extractor.h</vh></v>
</v>
<v t="ntallen.20080716155154.4"><vh>DC.h</vh>
<v t="ntallen.20080720213239"><vh>Simple Data Client</vh></v>
<v t="ntallen.20080720213239.1"><vh>Photon Data Client</vh></v>
<v t="ntallen.20080720213239.2"><vh>Data Client with Command Interface</vh></v>
</v>
</v>
<v t="ntallen.20070817133522.4"><vh>DC</vh></v>
<v t="ntallen.20070817133522.5"><vh>DG API and design issues</vh>
<v t="ntallen.20080624104326"><vh>Interfaces</vh>
<v t="ntallen.20080625152707"><vh>Command Interfaces</vh></v>
<v t="ntallen.20080624104326.1" a="E"><vh>Driver Interface</vh>
<v t="ntallen.20080624104326.2"><vh>Driver Class</vh></v>
</v>
<v t="ntallen.20080624104326.3" a="E"><vh>Driver Synchronization</vh>
<v t="ntallen.20080624104326.4"><vh>Blocking writes</vh></v>
<v t="ntallen.20080624104326.5"><vh>Non-blocking writes and ionotify</vh></v>
</v>
</v>
<v t="ntallen.20080707135523" a="E"><vh>Main</vh>
<v t="ntallen.20080707135523.1"><vh>Read Thread</vh></v>
<v t="ntallen.20080708133047"><vh>Write Thread</vh></v>
</v>
<v t="ntallen.20070823131008"><vh>data_queue (DQ)</vh>
<v t="ntallen.20080710162929"><vh>DQ hierarchy</vh>
<v t="ntallen.20080710162929.1"><vh>Commands</vh></v>
<v t="ntallen.20080710162929.2"><vh>Collection strategy</vh></v>
<v t="ntallen.20080908205900" a="E"><vh>rdr (or general extraction) Strategy</vh>
<v t="ntallen.20080909114112"><vh>Control Thread</vh></v>
<v t="ntallen.20080710162929.3"><vh>Output Thread</vh></v>
<v t="ntallen.20080909114112.1"><vh>Input Thread</vh></v>
</v>
</v>
<v t="ntallen.20080708165645.1"><vh>Will DQ provide type translation?</vh></v>
<v t="ntallen.20080623133120"><vh>DQ Semaphore</vh></v>
<v t="ntallen.20070823131008.1" a="E"><vh>Writer operations</vh>
<v t="ntallen.20080709115758"><vh>Initialization</vh></v>
<v t="ntallen.20070823131008.2"><vh>allocate_rows(n_rows_max)</vh></v>
<v t="ntallen.20070823131008.3"><vh>commit_rows(MFCtr, row_start, n_rows)</vh></v>
<v t="ntallen.20070823131008.4"><vh>commit_tstamp(MFCtr, time)</vh></v>
</v>
<v t="ntallen.20070823131008.5" a="E"><vh>Reader operations</vh>
<v t="ntallen.20070823131008.6"><vh>transmit_rows(n_rows)</vh></v>
</v>
</v>
<v t="ntallen.20070820135203"><vh>Collection</vh></v>
<v t="ntallen.20070822162630"><vh>rdr</vh></v>
<v t="ntallen.20070822162630.1"><vh>Inetin</vh></v>
<v t="ntallen.20070820135203.1"><vh>Everything else</vh></v>
</v>
</v>
</v>
</v>
</vnodes>
<tnodes>
<t tx="ntallen.20070319130904">@nocolor
</t>
<t tx="ntallen.20070319130904.1"></t>
<t tx="ntallen.20070319130904.2">Only a single writer (Data Generator) is allowed.
</t>
<t tx="ntallen.20070319130904.3">Data Generators (DGs) are where telemetry data enters the system. These programs open the TMbfr for write. TMbfr is limited to a single writer, so only one DG is allowed per instrument.

DGs also will read from the command server to receive commands.

The DG library will need to support basic timing functions. Collection needs timing in order to build the frame. Other DGs need timing in playback modes
</t>
<t tx="ntallen.20070319130904.4">Collection is the realtime DG which collects data from the instrument. Each Collection program is instrument-specific, and is compiled from TMC code.</t>
<t tx="ntallen.20070319130904.5">The Reader reads telemetry data from log files written by lgr. rdr is not instrument-specific.
</t>
<t tx="ntallen.20070319130904.6">Inetin retrieves telemetry data from a remote system via TCP/IP.
</t>
<t tx="ntallen.20070319130904.7">Data Clients (DCs) read telemetry data from TMbfr and process it in various ways.</t>
<t tx="ntallen.20070319130904.8">The Logger (lgr) writes telemetry data to disk. It reads commands from the Command Server for 'logging suspend/resume'.
</t>
<t tx="ntallen.20070319130904.9">Display programs read telemetry data from TMbfr and display it on screen as text or graphics.
</t>
<t tx="ntallen.20070319130904.10">Reads data from TMbfr and outputs it in some format. Generally does not process commands.</t>
<t tx="ntallen.20070319130904.11">Reads data from TMbfr and sends commands. Should receive any command info via TM stream.</t>
<t tx="ntallen.20070319130904.12">The command architecture consists of Command Sources, the central Command Server and Command Receivers.
Command Sources include algorithms and the keyboard client
Command Receivers are client programs that wish to receive commands.

The keyboard client and the command server are both compiled from the same source code generated by cmdgen that knows how to parse text commands and perform actions based on those commands. These are in turn linked with library functions (in tmlib or tmphlib?) to make appropriate executables</t>
<t tx="ntallen.20070320110353">Command server is experiment-specific, compiled from .cmd input by cmdgen. It accepts ASCII command sequences from clients, parses them and executes the specified code. In this version, that can include making the command available to other client programs.</t>
<t tx="ntallen.20070320121924">Defines command syntax and code to execute on command reception.
</t>
<t tx="ntallen.20070320135407"></t>
<t tx="ntallen.20070320135407.1">Will appear under /dev/huarp/$exp/cmd/$node
</t>
<t tx="ntallen.20070320135407.2">Could be combined with options.</t>
<t tx="ntallen.20070320135407.4">ASCII text, client-specific. Each message should end with a newline so it will play well with shell tools.
There will be a fixed maximum message length for all clients.
</t>
<t tx="ntallen.20070320135407.5">Will simply provide linked list with no real limit. However commands queued before a reader connects will be discarded.</t>
<t tx="ntallen.20070320140803">Each interface contains a queue
If no readers exist, no commands will be enqueued
Commands are dequeued when all current readers have received them or when the queue overflows
The first command written to the queue is numbered 1.
Queue records oldest command number and newest command number.
Each reader has a record of last command read.
</t>
<t tx="ntallen.20070320140803.1"></t>
<t tx="ntallen.20070320140803.2">Logged. Not reported back to the writer. Causes oldest command to be deleted.</t>
<t tx="ntallen.20070320140803.3">Logged. Could be reported back to writer. Command is not enqueued.</t>
<t tx="ntallen.20070320140803.4">To be reported to a reader if the queue overflowed while it was processing.</t>
<t tx="ntallen.20070320150524.1"></t>
<t tx="ntallen.20070320150524.2">Also compiled from cmdgen sources</t>
<t tx="ntallen.20070320150524.3">Does not see cmdgen source, but invokes the command server in test mode to test command syntax
</t>
<t tx="ntallen.20070320150524.4"></t>
<t tx="ntallen.20070320150524.5">Only one of these
</t>
<t tx="ntallen.20070320150524.6">Should be only one of these
</t>
<t tx="ntallen.20070320150524.7">Playback controls: Assuming only monotonic, no rewind. If we support rewind, then the rdr (DG) needs to get those commands too.</t>
<t tx="ntallen.20070320150524.8">One should be enouch
</t>
<t tx="ntallen.20070320150524.9">One
</t>
<t tx="ntallen.20070320150841"></t>
<t tx="ntallen.20070320150841.4">I believe this is done.</t>
<t tx="ntallen.20070322130922">I used the name 'lgr' for awhile, although that was obviously confusing.
This needs to be formally renamed and cleaned up. (08-05-16)</t>
<t tx="ntallen.20070322130922.1">This is not implemented. Should use tm_dev_name() from tmlib</t>
<t tx="ntallen.20070322130922.2"></t>
<t tx="ntallen.20070322130922.3"></t>
<t tx="ntallen.20070322160353">Everyone wants to get the Quit command. This one almost certainly requires multiple support, or else it is written to every interface.</t>
<t tx="ntallen.20070322160353.1">Examine current library for options
Usual message format includes:
    timestamp: hdr: severity: message

timestamp: Some sort of hook should be available for tweaking this. In playback, we want this to reflect the playback time, as opposed to the realtime, though we might want to mix the two. Perhaps playback time should be prefixed with something: &lt;00:00:00&gt;:

Ideally, lgr will check incoming messages to determine whether they have been properly formatted. If they don't have a timestamp, one should be added. If they don't have a header, maybe it can make one up?

Perhaps Timestamps should include the date. lgr could strip it out, but add a date stamp whenever it changes.

[[mm/dd/yyyy ]hh:mm:ss:][&lt;mm/dd/yyyy hh:mm:ss&gt;][hdr[.SEVERITY]:]message</t>
<t tx="ntallen.20070322160353.2"></t>
<t tx="ntallen.20070322160353.3">Memo cannot read commands from the command server and also accept log messages from the command server without risking a deadlock. The only command we're interested in is 'Quit.'</t>
<t tx="ntallen.20070322160353.4">Suppose I adopt the simple strategy of having Memo begin termination after at least one client has opened a connection and all clients have closed. Startup procedure would be to start Memo, then the command server, and then everything else.</t>
<t tx="ntallen.20070322180349">Monitor messages received. Figure out what the '0' command really is.
No idea, but simply terminating seems to work fine.
</t>
<t tx="ntallen.20070323134835"></t>
<t tx="ntallen.20070323134835.1"></t>
<t tx="ntallen.20070323134835.2"></t>
<t tx="ntallen.20070323134835.3">Probably common to all mountpoints
nparts_max, msg_max_size
other_func (for handling non-resource-manager messages. Probably not necessary for now)</t>
<t tx="ntallen.20070323134835.4">Unique to each mountpoint</t>
<t tx="ntallen.20070323134835.5">unique to each mountpoint
count records the number of OCBs using this attribute. zero should mean all clear
Probably want to extend to keep track of open handles for this resource.</t>
<t tx="ntallen.20070323134835.6">The mountpoint structure is where the ocb_calloc and ocb_free functions are specified. The structure is optional, so it is only needed if certain options need to be specified or if you want to extend the ocb structure. We may need to do that for TMbfr and/or the Command Server, but perhaps not for the Logger.
</t>
<t tx="ntallen.20070330134656"></t>
<t tx="ntallen.20070330134656.1">Each command receiver is a command type.
For each command type, there is a mountpoint and a command output queue.
The mountpoint is /dev/huarp/$exp/cmd/$node

    Don't maintain list of OCBs with each command. Just maintain a reference count
    OCBs still point to command. When command is serviced (written to reading client)
      the current command reference count is decremented
        If it is the first command and the reference count is zero, recycle
      the OCB's command link is pointed to the next command
      the next command's reference count is incremented
    The only time a client will block is when the command queue is empty, so then we
    can maintain a list of waiting OCBs, but we don't have to keep it with each command.
    When a new command is received, send replies to all waiting clients and remove them
    from the waiting list.
    
    We also use the resource manager library to maintain a list of clients with
    outstanding select/ionotify requests.

    In this case, OCBs need
      next_command pointer
      rcvid (to indicate blocking)
      next_ocb pointer (for blocked OCBs list)
    Command needs
      reference count
      next_command pointer
    Each mountpoint (RESMGR_HANDLE_T)
      list of blocked OCBs

    In the ocb_alloc func, point to oldest command and increment reference count
    In ocb_free, decrement reference count (and possibly release the command)</t>
<t tx="ntallen.20070330134656.3"></t>
<t tx="ntallen.20070330134656.4">Unique to each open file handle. Points to the iofunc_attr_t (so you can tell what resource you're accessing.)
May need to extend if necessary to record state for this handle.
</t>
<t tx="ntallen.20070330134656.5">In single-threaded approach:
    On write, we should queue the write, then process any pending reads on that resource
        queue the data
        reply successfully to the writer
        process pending reads
        return(_RESMGR_NOREPLY);
    On read, if data is present, reply immediately, otherwise queue:
        save ctp-&gt;rcvid
        return(_RESMGR_NOREPLY);
In multi-threaded approach:
    On read, if data is not present, block on thread-specific semaphore.
    On write, queue the write and then wake up blocked reader threads.
    This assumes readers haven't locked any structures</t>
<t tx="ntallen.20070403140218"></t>
<t tx="ntallen.20070403140218.1"></t>
<t tx="ntallen.20070403140218.2">Probably common to all mountpoints. Initialized in main()
nparts_max, msg_max_size
other_func (for handling non-resource-manager messages. Probably not necessary for now)</t>
<t tx="ntallen.20070403140218.3">Unique to each mountpoint</t>
<t tx="ntallen.20070403140218.4">unique to each mountpoint, needs to be extended to include list of blocked OCBs
#define IOFUNC_ATTR_T struct ioattr_s

Extended to include:
    blocked; // list of blocked OCBs
    commands; // list of pending commands
    next; // link to another handle

</t>
<t tx="ntallen.20070403140218.5">Defines how ocb structure is extended. Can be common to all mountpoints

The mountpoint structure is where the ocb_calloc and ocb_free functions are specified. The structure is optional, so it is only needed if certain options need to be specified or if you want to extend the ocb structure. We may need to do that for TMbfr and/or the Command Server, but perhaps not for the Logger.
</t>
<t tx="ntallen.20070404111542">Reader initializations should be combined in a function called at startup.
Calling of initialization functions is generally handled via oui. In this case, where we expect almost every command server to initialize reader interfaces, we might modify the command server oui to call a known function.

Reader initialization will look something like:
    
    IOFUNC_ATTR_T *if_indxr;
    IOFUNC_ATTR_T *if_scdc;
    
    void cis_interfaces( void ) {
      if_indxr = cmdsrvr_setup_rdr( "indxr" );
      if_scdc = cmdsrvr_setup_rdr( "scdc" );
    }
    
    { cmdsrvr_turf( if_indxr, "indexer command text" ); }

The fact that this is so formulaic suggests we could make the specification easier. Something like:
    
    %INTERFACE &lt;indxr&gt;
    %INTERFACE &lt;scdc&gt;
    
    { cmdsrvr_turf( if_indxr, "indexer command text" ); }

Allowing INTERFACE definitions on separate lines means they can be further separated into multiple files.</t>
<t tx="ntallen.20070404111542.1">/dev/huarp/Exp/cmd/server
Maximum command length arbitrary (256)
Command messages are all ASCII, terminated by newline
One command per write()
Use an optional prefix:
    [ '[' mnemonic [ ':' [T][Q] ] ']' ] command
    '[' [ mnemonic ] ':V' version ] '\n'
mnemonic is the sender's mnemonic to be passed on to the log when command is received
</t>
<t tx="ntallen.20070404111542.2">For tmcalgo, we can play all sorts of games, but for file slurping, we need realtime feedback.
Can I return an error code and log the actual text?

Let's try for returning an error code. Server should produce the verbose error message to the log, but the client really only needs to know whether or not the command is correct.
</t>
<t tx="ntallen.20070404165230">This has been implemented and tested, and is now part of the command server library functions.
I will be using this capability in the DG code. We may find we need to add support for SELECT
in TMbfr.</t>
<t tx="ntallen.20070404165230.1">When Quit is received, run queues on all clients returning zero bytes and return zero bytes to anyone about to block. Whenever an OCB is closed, check to see how many remain open. When the number drops to zero, we can quit.</t>
<t tx="ntallen.20070404165230.2">Not clear whether this is still necessary.</t>
<t tx="ntallen.20070404221945"></t>
<t tx="ntallen.20070404221945.1"></t>
<t tx="ntallen.20070404221945.2"></t>
<t tx="ntallen.20070404221945.3"></t>
<t tx="ntallen.20070404221945.4"></t>
<t tx="ntallen.20070404221945.5"></t>
<t tx="ntallen.20070404221945.6"></t>
<t tx="ntallen.20070404221945.7"></t>
<t tx="ntallen.20070404221945.8"></t>
<t tx="ntallen.20070404221945.9"></t>
<t tx="ntallen.20070409132623">Flash app to display different modes of operation</t>
<t tx="ntallen.20070409132623.1"></t>
<t tx="ntallen.20070409132623.2"></t>
<t tx="ntallen.20070409132623.3"></t>
<t tx="ntallen.20070409132623.4"></t>
<t tx="ntallen.20070409132623.5"></t>
<t tx="ntallen.20070409132623.6">Data should highlight the data flow</t>
<t tx="ntallen.20070409132623.7">Command highlights the command flow</t>
<t tx="ntallen.20070409132623.8">Selecting an application displays a synopsis of its function and pointers to further information</t>
<t tx="ntallen.20070409132623.9">Memo is a special case.
Within any of the modes, selecting Memo should highlight the message links from active apps to Memo
</t>
<t tx="ntallen.20070409133739"></t>
<t tx="ntallen.20070409133739.1"></t>
<t tx="ntallen.20070409133739.2"></t>
<t tx="ntallen.20070409133739.3">Apps
DataLinks
CmdLinks
MemoLinks

For Each App and Link, need to know which configurations apply
For Apps, simply need to know which configurations
For Links, they are present if both their source and destination apps are present
Could be calculated or pre-calculated
Simplest implementation I can think of encodes object name and bit-mapped object type and configuration modes

Simpler approach is to use a different frame-range for each configuration and use layers for:
    Applications
    DataLinks
    CommandLinks
    MemoLinks

This requires no encoding</t>
<t tx="ntallen.20070411152334"></t>
<t tx="ntallen.20070413134915"></t>
<t tx="ntallen.20070413134915.1">How shall I organize the source code? I'd like to have some sort of hierarchy, but that's bucking the IDE's approach.
Let me try to lay out a hierarchy, and see if it can't work.

Each node below here will be an IDE project. If there are sub-nodes, they will be extra executables

Avoid Recursive Makes wherever possible
Use automake/autoconf
  subdir-objects option, etc.</t>
<t tx="ntallen.20070425144317">The frustrating thing is that the documentation on the Makefile conventions used clearly documents more layers than are implemented by the IDE. For any but the simplest projects, understanding the Makefile conventions is very useful, so having the two systems out of agreement makes life more complicated.

That said, I think I have figured out how to create a QNX C Project with a SECTION layer.

1: Create the Project in the IDE
2: Open a shell and delete the target processor subdirectory(ies)
3: Edit Makefile and change LIST=CPU to LIST=OS
4: run: addvariant section1 x86 o
   [ replace section1 with the desired section name(s) ]
   [ replace x86 with the appropriate processor(s) ]
   [ replace o with the appropriate variant(s) ]
5: Edit Makefile again and change LIST=OS to LIST=SECTION
   [ this step may not be necessary, but I had some problem under
     neutrino when I didn't do this... ]
6: Edit common.mk and change:

   include $(MKFILES_ROOT)/qmacros.mk

  to

   EXTRA_SILENT_VARIANTS=$(SECTION)
   include $(MKFILES_ROOT)/qmacros.mk
   NAME=$(SECTION)

7: Refresh the project in the IDE

NOTES: addvariant does nothing unless it finds LIST=OS, so if you want to add variants later, you have to make that change in the root Makefile. addvariant clearly doesn't understand sections, but it is still useful for adding the right Makefiles at each level. I'm taking advantage of the fact that addvariant *does* support the OS layer, which I don't need. I'm pretending that the section layer is an OS layer. For deeper nesting, manual intervention would be the thing to do.
</t>
<t tx="ntallen.20070425144317.1"></t>
<t tx="ntallen.20070425144317.2">Functions that pertain directly to the data acquisition system. Probably depends on nortlib.</t>
<t tx="ntallen.20070425144317.3">Data acquisition functions that depend directly on Photon. If I adopt a server-based approach, I should be able to limit the number of applications that depend directly on this library.</t>
<t tx="ntallen.20070425144317.4">General utility functions. Should be mostly portable between operating systems.</t>
<t tx="ntallen.20070430134037">Added autoconf/automake support, but turns out it isn't backwards compatible for a couple reasons:
    1. -lnort needs to be -lnortlib on QNX4. Could check for either library and take whatever is found.
    2. Lib check for compiler_init_options() returns undefined symbols on QNX4. I've added yyin.c and optstr.c to nortlib2, and perhaps they need to be back-ported to QNX4.
Fixed those two, but now running into a sed incompatability.

Trying to port recent GNU sed
need to edit bootstrap.sh
  need to add HAVE_LIMITS_H
  need to define HAVE_SYS_FILE_H
  need to add '1' to blank defines
  need to add -lunix -N1M to link step
  need to #define inline

When running configure, probably need to pass in -lunix -N1M
./configure LDFLAGS="-lunix -N1M" LD=wlink
Getting lots of "Memory exhausted" complaints from sed
</t>
<t tx="ntallen.20070501165557"></t>
<t tx="ntallen.20070501165557.1">Some flag passed to the linker to embed the library path into the executable
ld flag -rpath /usr/local/lib
LDFLAGS=-Wl,-rpath /usr/local/lib -L/usr/local/lib -ltm -lnort
CFLAGS=-I/usr/local/include
</t>
<t tx="ntallen.20070501165557.2">/dev/huarp/&lt;Exp&gt;/cmd/&lt;server&gt;</t>
<t tx="ntallen.20070501165557.3">My guess is that when CLIENT is not defined, we don't need any interface functions.
Right now, server is getting some output because DISPLAY_EOL is being invoked.</t>
<t tx="ntallen.20070501165557.4">Modify this to skip Phab. It's pretty basic:
    PtInit(NULL)
    PtWidget_t *w = tbl_window("name", w,h); // may want to select some other attributes
    // attach keyboard event to window
    PtAddFilterCallback(w, ph_EV_KEY, my_key_event, NULL);
    PtWidget_t *cmd = tbl_field( w, "cmd", x, y, w, h );
    PtWidget_t *prompt = tbl_field( w, "prompt", x, y, w, h );
    // figure out how to draw my funky prompt symbol
    // PgDrawPolygon()
    PtRealizeWidget(w);
    // phinitfunc();  // This is what did all the drawing in CRphdisp.c
    PtMainLoop();

Link with -ltmph -ltm? -lph</t>
<t tx="ntallen.20070502121159">QNX4 nortlib had nl_make_name() and nl_find_name() for building names that were then searched for.
nl_find_name() actually opened a connection. Since the connection is now an fd, the corresponding function would have to take open flags (O_RDONLY, etc.)

The QNX6 function for building a name is tm_dev_name()
The function for establishing a connection is tm_open_name( fqen, node, flags )</t>
<t tx="ntallen.20070502121159.1"></t>
<t tx="ntallen.20070502121159.2"></t>
<t tx="ntallen.20070502121159.3"></t>
<t tx="ntallen.20070502121159.4"></t>
<t tx="ntallen.20070502121159.5">Just because it should be easy to add via oui. Use nl_error() now, and that will map to memo seamlessly.</t>
<t tx="ntallen.20070502121159.6"></t>
<t tx="ntallen.20070508171951"></t>
<t tx="ntallen.20070508171951.1"></t>
<t tx="ntallen.20070508171951.2"></t>
<t tx="ntallen.20070508171951.3"></t>
<t tx="ntallen.20070508171951.4"></t>
<t tx="ntallen.20070508171951.5"></t>
<t tx="ntallen.20070508171951.6"></t>
<t tx="ntallen.20070508171951.7"></t>
<t tx="ntallen.20070509151554">given package name 'foo', oui currently looks for
  foo.oui
  $path/foo.oui
  oui/foo.oui
  $path/oui/foo.oui

where $path is a searchenv() call on INCLUDE
I'm inclined to go with:
    foo.oui
    oui/foo.oui
    $(datadir)/foo.oui
    $(datadir)/oui/foo.oui</t>
<t tx="ntallen.20070509151554.1">Do not require an interface definition if SERVER alone is defined</t>
<t tx="ntallen.20070509151554.2"></t>
<t tx="ntallen.20070509151554.3">root.cmd at least, but it needs editing</t>
<t tx="ntallen.20070509151554.4">Let's avoid including appgen.mk. Include it directly into the Makefile instead.
autotools gives explicit link instructions:
    cmdgen$(EXEEXT): $(cmdgen_OBJECTS) $(cmdgen_DEPENDENCIES)
        @rm -f cmdgen$(EXEEXT)
        $(LINK) $(cmdgen_OBJECTS) $(cmdgen_LDADD) $(LIBS)
Hence it wouldn't be unreasonable to add the appropriate usemsg and/or promote instructions
</t>
<t tx="ntallen.20070509151554.5">LDFLAGS needs -Wl,-rpath -Wl,/usr/local/lib
Need to promote, add usage</t>
<t tx="ntallen.20070524163205">What is the difference between the telemetry stream and the TM stream as returned from TMbfr?
</t>
<t tx="ntallen.20070524163205.1"></t>
<t tx="ntallen.20070524163205.2">Timestamps allow date/time to high precision without recording YYMMDDHHMMSS in every frame.</t>
<t tx="ntallen.20070524163205.3">App is assumed to match local definition. Can only check that MFCtr/Synch make sense releative to TM info.</t>
<t tx="ntallen.20070524163205.4">Might as well use a format similar to TMbfr's output</t>
<t tx="ntallen.20070524163205.5">Same here, although we might choose to add some sort of checksuming</t>
<t tx="ntallen.20070524163205.6">If Inetin and rdr use the TMbfr format, all DGs should</t>
<t tx="ntallen.20070524163205.7">TMbfr presumably will understand at least the four basic data formats, TMTYPE_DATA_T[1-4]
Should it:
    Decide based on the format which output format to use, or
    Respond to client requests in order to provide alternate formats

At the moment, I don't know that there is any motivation to provide a less compact format, except for the purpose of breaking up a long record into shorter records. A telemetry output program might need to add MFCtr and Synch to a T3 record, but that is going to be pretty rare. TMbfr should be able to promote a stream from T1 to T3 or T4 if it is capable. If it receives a T1 or T2 stream, it should perform sanity checks to make sure MFCtr and Synch agree with the spec (although these should be redundant). In T4 streams, checksum should be checked (or might be optionally checked.)</t>
<t tx="ntallen.20070524163205.8"></t>
<t tx="ntallen.20070524163205.9">There are three basic modes of operation worth considering:
    fast realtime response
    optimal batch performance
    playback regulated output
Fast realtime repsonse is desired by display programs and algorithms that need to respond to current conditions in a timely manner
Optimal batch performance delivers larger chunks of data to programs that don't need realtime response such as lgr and ext
Regulated output is used for playback or remote display to emulate realtime operation, but also support DVR controls

Playback control is a feature of the DG now, so TMbfr doesn't really know whether or not the input is regulated or not. Similarly, the DG doesn't know what sort of readers are on the TMbfr. I think it will be up to the operator and the script creators to make sure each program runs in the optimal mode for the task at hand.

    /dev/huarp/Exp/TM/DG writer interface
    /dev/huarp/Exp/TM/DCf fast reader interface
    /dev/huarp/Exp/TM/DCo optimal reader interface

In fast forward, DCf and DCo are treated essentially the same. The DG will write largish chunks of data, and they will be passed through to the readers.
</t>
<t tx="ntallen.20070524163205.11">This is an idea to facilitate more playback options. Clients that deem incomplete data to be OK could receive only occassional updates during fast forward or search operations. Certain clients are apt to be more sensitive to the complete data set, specifically algorithms that maintain state information. These would be set to receive the complete data set and would also be prevented from seeing non-monotonic data.</t>
<t tx="ntallen.20070525114357">/dev/huarp/$Experiment/TM/DG write only
/dev/huarp/$Experiment/TM/DCf read only
/dev/huarp/$Experiment/TM/DCo read only
</t>
<t tx="ntallen.20070525114357.1">We can initialize the MD list immediately, and each client OCB can refer to the one active empty MD and indicated that 0 TimeStamps have been processed.
Until we hear from the DG, we don't know how much buffer space to allocate in the data queue.</t>
<t tx="ntallen.20070525114357.2">When the initial configuration arrives, we can make decisions about what data format to use for output and hence what buffer dimensions to use.

If nrowminf == 1 &amp;&amp; mfc_lsb == 0 &amp;&amp; mfc_msb == 1, use T3
else if nrowminf &gt; 1, use T2
else use T1

Incoming data may always come in in T1 or T2, so we'll need to be able to translate between formats

DG initialization also includes the starting TimeStamp, so we can initialize the TS list and kick all of the client OCBs</t>
<t tx="ntallen.20070525114357.3">Data is stored in rows (i.e. smallest storage unit is a row) Actual storage size depends on TM format and choice of output format. T3  rows are shorter by 4 bytes. Data is identified by Qrow, which runs from 0 to max_Qrows-1.</t>
<t tx="ntallen.20070525114357.4">Metadata records aka MD aka dq_descriptor or dqd

Starting coordinate {
  metadata_serial_number: [might not be necessary]
  starting_Qrow: Which Qrow contains the first row of data for this block
  ref_count: How many OCBs are pointing to this record
  TS_serial_number: starts at 1
  n_Qrows: How many Qrows in this block. May wrap in queue
  MFCtr, Row: What is the MFCtr and Row index for the starting Qrow of data
  Qrows_expired: How many Qrows have been expired from this metatdata block
}

TimeStamps don't expire until all the data they pertain to expire. That way new clients can always receive the TimeStamp for the oldest data on record

A single metatdata record can be used for an extended period of time. The Qrows_expired field is used to note that rows have been expired. In each client OCB, a record is kept of which metatdata block is current and how many rows within that block have been delivered.
A Metadata record is active if it is the most recent metatdata record and hence might receive additional data

A metadata record is empty if it is inactive and all of its data records have expired (or equivalently, n_Qrows == 0)
  A MD can only be empty if all preceeding MD records are empty as well

TimeStamp Metadata records can be expired when no longer referenced by active or non-empty MD
  or perhaps we just merge old MD records so new clients can note that they did not see the
  start of data.

An empty, inactive, unreferenced MD can expire. Will only actually expire it if it is first in DQD_Queue, but will skip over empty inactive dqd's on read. Could theoretically be merged into the preceeding empty MD record by adding its number of expired rows to the preceeding MD's, but the only point would be to count rows and let incoming clients know that they have missed some data. (Note that no current clients would know what to do with that information.) Could instead maintain a global expired rows count.

To expire, dqd must meet three conditions:
    1. n_Qrows == 0
    2. ref_count == 0
    3. Must be first in DQD_Queue

These conditions might initially arise:
    1. On write, when rows are expired
    2. On read, when moving to a new dqd (dq_deref())
    3. On reader's close (dq_deref())

When a MD becomes empty (as data rows are expired) reduce ref count on associated TS. TS will expire if unreferenced.
When OCB points to new MD, update ref counts. If old MD is now empty and unreferenced, do merge check.

Before the first actual TM data arrives, there will be no queued timestamps or data records.
When the tm_info_t arrives, we can create the first timestamp record and the first MD record which references it. The MD will have n_Qrows of zero indicating that MFC, rownum, etc are not yet defined.

[We could either create a starting dq_descriptor with a flag indicating it is uninitialized, or we could wait to create it until it can be initialized (when the first data arrives) The former approach means initialization takes place in two places for no particular gain.
Well, one gain might be that we can immediately reference the current TS through the current MD, and we can immediately transmit tm_info_t. Actually, we need the 'uninitialized MD' flag whenever a new timestamp arrives, since we don't know what MFC, etc. will arrive. If n_Qrows is zero, we can modify the MFC, rownum, etc.]

When first data arrives, initialize first MD, visit any queued OCBs and link them into this record
</t>
<t tx="ntallen.20070525114357.5">next
TS_serial_number
unixtime
MFCtr
</t>
<t tx="ntallen.20070525114357.6">Which Metadata block: store as pointer
How many rows have already been processed?
Next pointer for list of pending requests

We don't advance to another metadata block until there *is* another metadata block to advance to. Even if we've processed all of the current block's data, it might be augmented in the future.

When we first start, there might not be even one metadata record, so no OCBs will point to anything.
</t>
<t tx="ntallen.20070525132754">Need provision for handling partial frame requests
Need to be able to buffer the header and at least one row so a data request for 1 byte can buffer the output data
These allocations cannot occur before the DG is initialized. But of course the DG interface needs to be ready to accept the tm_info_t structure, potentially as a partial frame. First record must be tm_info_t, so we could read it directly into a tm_hdr_t and then into tm_info.</t>
<t tx="ntallen.20070529132018">Need to differentiate between nodes
Need to maintain a list of pending reads. Should I do it here, or globally? Ideally should handle highest priority first.</t>
<t tx="ntallen.20070529132018.1">Just need to make sure only one open is allowed.</t>
<t tx="ntallen.20070529132018.2">On the writer, we need a scratch buffer for interpreting incoming messages, and we may as well use the partial buffer for this purpose.

I don't necessarily need to buffer an entire tm_msg_t. For example, if the tm_msg_t actually exceeds the size of the data queue, that wouldn't make sense. I expect that the underlying OS functionality will break a big message up into smaller messages. We need to use the partial buffer to handle this.

Partial buffer should be big enough to hold the tm_hdr_t, the largest data header (T2), and one row of data.

The smallest tm_msg_t is 10 bytes (Tstamp).
The first 6 bytes include all the information we need to determine the total message size[, but rather than waste time on multiple syscalls, read in up to 64 bytes (tm_info_t), since that will include all the info we need to decide how to proceed. Might want to modify that number upwards depending on nbrow. If it turns out most frames arrive in, say, 65 bytes, we might want to go ahead and get the whole thing.] Only need to read tm_info_t once at the beginning, so it is foolish to optimize this operation for that case. Instead, optimize for incoming data. Could adjust based on the data type actually being used (i.e. DG is probably going to use the same data type throughout, so once we've received one data block, we can guess what the future data blocks will hold.)

Rego: tm_info_t must be the first type read and will never recur, so don't need to use it as a benchmark
12 bytes will include all header data without trying to retrieve any data. Data will go elsewhere, so there is little advantage in reading it here.

Read in up to 12 bytes. If at least 4 have been read, we can check if we have all the header data we need:
    TM_TYPE_INIT: 64
    TM_TYPE_TSTAMP: 10
    TM_TYPE_DATA_T1: 6
    TM_TYPE_DATA_T2: 10
    TM_TYPE_DATA_T3: 8
    TM_TYPE_DATA_T4: 12
If we don't, note the partial frame. If we do, proceed with processing
INIT and TSTAMP processing is straightforward, since all the data is present in the message.
For Data messages, determine the actual message size and compare it to the write size


</t>
<t tx="ntallen.20070529133623">In this state, we are waiting to receive a complete header. The state information includes how many bytes are in the partial header (and may be zero) We can read up to 10 bytes if they are available. Some decisions can be made with fewer bytes read, but there is very little advantage in doing so, since no message will be less than 10 bytes.</t>
<t tx="ntallen.20070529133623.1">In this state, we have received a complete header, and may have received some data or not. All complete rows have already been entered into the data queue. [Any partial row is stored in the partial buffer.] Partial rows can be stored directly in the Data_Queue (past the end of the queue) since as writer we control that end of the queue. The size and destination of the initial read is calculated based on the current status.

If partial_data + write_size &gt;= nbrow, prepare to write data into the data queue. Copy partial data into beginning of target and read remaining fraction plus whole rows from the message.</t>
<t tx="ntallen.20070531154309">When read request arrives, determine whether it can be handled immediately. If not, block.
Whenever data arrives, check queued read requests to see if they can be satisfied. If so,
process them.

If tm_info has not been written yet, OCB will not have a dq_descriptor
</t>
<t tx="ntallen.20070531162708">Reading data into tm_info. This should only be used if we're getting tm_info in tiny bits.

process_tm_info();
As soon as tm_info has been received, we can decide what data format to output, how much buffer space to allocate and in what configuration. We can then create the first timestamp record (with the TS in the tm_info) and the first dq_descriptor, albeit with no Qrows, but refrencing the the first timestamp. Then we can check to see if any readers are waiting, and initialize them.

T1: Complete minor frames
T2: Complete rows
T3: Truncated rows

if ( mfc_lsb == 0 &amp;&amp; mfc_msb == 1 &amp;&amp; nrowminf == 1 ) use T3
else if ( nrowminf == 1 ) use T1
else use T2</t>
<t tx="ntallen.20070531163245"></t>
<t tx="ntallen.20070531163245.1">Actually may not need states per se.

If there is partial data present ( ocb-&gt;part.nbdata ) then send it
else If dqd is not set, we need to transmit the TMTYPE_INIT record
else If current dqd is done and next dqd has a new TS, transmit the new TS
else transmit from the current dqd

</t>
<t tx="ntallen.20070531163245.2">Store the size of the header we are transmitting (nbhdr) and the current offset. Use the OCB's tm_hdrs_t struct. Also buffer the data portion of the record in the buffer and set nbdata.

If offset is zero, we're just starting {
  Initialize the tm_hdrs_t and set nbhdr and nbdata
  If the entire request can be satisfied immediately {
    set up the buffers to send the data, and leave offset at zero and state at Partial Header
    return
  } else {
    copy the data into the partial buffer (and initialize it if necessary)
  }
}
set up buffers to send partial data and possibly switch to Partial Data state
</t>
<t tx="ntallen.20070531163245.3">I think this state will only be used for writer, or maybe it will be eliminated altogether.

Used when transmitting the initial tm_info struct(? how is the tstamp handled?)
</t>
<t tx="ntallen.20070531163245.4">Only used when transmitting a single row. All larger requests will be processed in integral numbers of rows.
</t>
<t tx="ntallen.20070601102213">On second thought... it doesn't necessarily make sense to handle playback timing in TMbfr when it could more easily be handled in the DG. The DG must already monitor the command channel to handle start/quit, and we already need to implement timing there to handle collection, so it should be fairly trivial to provide it for other DGs. In that case, there are no command requirements for TMbfr, which is as it should be.

===old discussion follows===

As discussed elsewhere, in realtime operation TMbfr will not handle any commands. It will forward all data that is written, and it will shutdown gracefully when the write stream is closed. By 'gracefully' I mean it will signal EOF to all readers, and won't actually shut down until all of the reader streams are also closed.

In playback or remote operation, it will monitor commands from the command server for data regulation, but it will not accept a QUIT command via that route because it is difficult to signal back to the DG that the channel should be closed. Instead, the DG should monitor its own command channel for QUIT.

What if the DG never starts up? cat /dev/null &gt;/dev/huarp/Exp/TM/DG
</t>
<t tx="ntallen.20070611133034">When processing data we have:
    n_rows in ocb-&gt;part.hdr.s.u.dhdr.n_rows
Determine how many complete rows we can handle in one pass from the current message
  nr = n_rows
  if ( rows_to_end_of_queue &lt; nr ) nr = rows_to_end_of_queue
  look at nbytes in the message, and limit to whole rows
Set ocb-&gt;part.nrows_receiving = nr
  n_rows -= nr
  ocb-&gt;part.nbdata = nr * nbrow?
  ocb-&gt;part.dptr = end_of_the_queue
  
When nbdata == 0, update Data_Queue with nrows_receiving new rows, then reassess status</t>
<t tx="ntallen.20070611133034.1">Copy straight in. T1 output does not include calculation of MFCtr, so there are no requirements for consecutive frames.</t>
<t tx="ntallen.20070611133034.2">Should be a straight copy, but need to verify MFCtr, Row_num
T2 output does require that frames be consecutive, so we need to read in the rows and then check them to make sure they belong with the previous records.

Hmmm. The message is guaranteed to have whole minor frames, but the segment going into the queue may not. I guess for both T1-&gt;T2 and T1-&gt;T3, the partial buffer should be big enough for a minor frame.

No, a simpler solution is to guarantee that total_Qrows is divisible by nrowminf. This solution works if and only if the input stream is consistently T1. If the DG slipped in a T2 partial frame, it would throw the whole thing off. There is no reason why a real DG would shift from one data type to another mid-stream. Maybe I should make that illegal. I could select data_state_init and data_state_eval functions once and access them via function pointers.</t>
<t tx="ntallen.20070611133034.3">Need to go row-by-row, verify MFCtr

This case requires considerable kluging.
Data will be copied into the partial buffer one row at a time, then MFCtr and SYNCH will be extracted, and the rest of the row will be copied into the queue. nb_queue and off_queue will need to be fudged before and corrected after each row.
</t>
<t tx="ntallen.20070611133034.4">Not likely. Could be illegal.</t>
<t tx="ntallen.20070611133034.5">Copy straight in, then verify continuity with previous records</t>
<t tx="ntallen.20070611133034.6">Not likely, could be illegal (i.e. T2 only applies when nrowminf &gt; 1)</t>
<t tx="ntallen.20070611133034.7">Won't happen</t>
<t tx="ntallen.20070611133034.8">Won't happen</t>
<t tx="ntallen.20070611133034.9">Copy straight in. Verify consecutive, etc.</t>
<t tx="ntallen.20070612165620">Can leave io_write in several states:
    Processed entire message and complete record
    Processed entire message, partial record
    Not done processing message (queue is full, writer is blocked)
</t>
<t tx="ntallen.20070612165620.1">Write a DG synthesizer to exercise different modes of operation.
Take tm.dac or text definition file as input
Allow override of output data format
Introduce scripted gaps, etc.

DC receiver (perhaps similar to lgr) to log the data as it comes in, perhaps taking it back to raw format or just reporting the pertinent info about the data. Could report contiguous rows and cksum, for example. Use a common summary library.</t>
<t tx="ntallen.20070612220750">Save state across invocations.
 States include
  HEADER
    ocb-&gt;part.nbdata bytes expected to ocb-&gt;part.dptr
  INFO
    ocb-&gt;part.nbdata bytes expected to ocb-&gt;part.dptr
  DATA

also
  ocb-&gt;write.rcvid // writer
  ocb-&gt;write.msgsize // bytes remaining in message
  ocb-&gt;write.msgoffset // offset within message

DATA state is challenging because we have the data record, the message
and the target queue buffer that may all be overlapping in odd ways.
If we come to the end of the record (nb_rec == 0) we go back to
the HEADER state. If we come to the end of the message (
ocb-&gt;write.msgsize == 0 ) we unblock the writer. If we come to the end
of the queue space, (nb_queue == 0) we try to find some more (If the
queue isn't full, proceed with the next block. If it is full and we're
non-blocking, then expire enough rows to hold the rest of the message

io_write( nb_msg ) {
  assert( ocb-&gt;part.nbdata &gt; 0 ); // ??
  while (msgsize &gt; 0 &amp;&amp; nbdata &gt; 0) {
    read min(nbdata,msgsize) to ocb-&gt;part.dptr
    update nb_msg, off_msg, nbdata, dptr
    if ( state == DATA ) {
      update nb_rec, off_rec, nb_queue, off_queue
    }
    if (nbdata == 0) {
      switch ( state ) {
        case HEADER:
          process_header
          switch (hdr.tm_type) {
            case TMTYPE_INIT:
            case TMTYPE_TSTAMP:
            case TMTYPE_DATA_*:
              initialize data state
              evaluate data state // does not actually move data
              copy data from header if necessary
          }
          setup to read more data as necessary
        case INFO:
          process_info();
          switch back to HEADER
        case DATA:
          evaluate data state
      }
    }
  }
  if (msgsize == 0) MsgReply();
  if (rows_arrived) run_read_queue();
}

initialize data state {
  nb_rec
  off_rec
  nb_msg
  off_msg
  nb_queue
  off_queue
  if T1-&gt;T3, make sure write buffer is allocated
}</t>
<t tx="ntallen.20070706110550">When data is coming in, we need to know how much of the old data has already been processed (at least in the blocking case. In the non-blocking case, we just take what we need.) Hence we need to know which reader has read the least. Probably the most efficient data structure for doing that is a heap. The min value is kept at the root, and there are two children on either side, each with values greater than or equal to the root. When a node's value changes, it can percolate up or down.

heap functionality

Each ocb records how many Qrows have been processed in the current dqd
(ocb-&gt;data.n_Qrows) There will be multiple readers for each dqd, and
we need to be able to keep track of the minimum value of
ocb-&gt;data.n_Qrows among those readers.

Events:
  ocb enters dqd
    increment reference count
    enter ocb's n_Qrows into the heap and adjust
  ocb reads some data
    n_Qrows increases, so adjust heap
  ocb leaves dqd
    decrement reference count
    remove ocb's n_Qrows from the heap and adjust

0 root
1          2
3     4    5      6
7  8  9 10 11 12  13  14

children are 2n+1 and 2n+2
parent is (n-1)/2

Each ocb needs to know it's position in the heap.
Any adjustment of the heap needs to 

Shouldn't bother with heap overhead in nonblocking case. The
decision can be made on the first write.
</t>
<t tx="ntallen.20070815151915"></t>
<t tx="ntallen.20070815151915.1">cmdgen is compiled and tested
tmlib has appropriate functions to generate a cmdsrvr
  I *think* tmlib has functional cmd client functions (command senders)
tmphlib has functions to support a keyboard client

DG is first command receiver. Currently implemented directly in modules in QNX6/DGdev, but will be moved into tmlib soon.

May want to add general library routines for receiving commands.

All of these require appgen support


</t>
<t tx="ntallen.20070815151915.2">TMbfr is operational. Will need further work to support memo, additional data formats
tmc is functional.
DG_data.cc: Need to fully implement TM 'Receive'
lgr: Need to write it
rdr: Need to write it
ssp: Need to test it
qcli: Need to write it
subbus: Need to write it
</t>
<t tx="ntallen.20070815151915.3">For setuid root, need to link with -rpath to find .so in /usr/local/lib:
    LDFLAGS=-Wl,-rpath -Wl,/usr/local/lib

Get a lot of unresolved symbol errors when linking c++ stuff. Apparently necessary to get all the options straight. Now using:
    VER=3.3.5
    TGT=-V$(VER),gcc_ntox86_cpp -lang-c++
    CFLAGS=$(TGT) -I... -Wall -g
    LDFLAGS=-L... -M
    LIBS=-ltm -lnort

and the make rule for the binary:
    cc $(CFLAGS) $(LDFLAGS) -o name $(OBJS) $(LIBS)
</t>
<t tx="ntallen.20070817133522"></t>
<t tx="ntallen.20070817133522.1">Original design documentation for DRing operation is lost: it was in agenda format and never extracted. But we've got the source code!</t>
<t tx="ntallen.20070817133522.2">These functions are all provided by colmain.skel. Non-tmc DGs probably have hand-crafted versions.

main() {
  oui_init_options() -&gt; DG_init();
  DG_operate() -&gt; DG_other(), DG_get_data(), DG_s_data();
}
DG_DAScmd()
DG_other() -&gt; Collect_row()
DG_get_data() -&gt; DG_s_data(), DG_s_tstamp()
Collect_row()

</t>
<t tx="ntallen.20070817133522.3"></t>
<t tx="ntallen.20070817133522.4">library functions:
    TM_read_stream() Opens fd and reads until EOF. Calls:
        TM_quit()
        TM_data() -&gt; TM_row()
        TM_init()
        TM_tstamp()
    Default versions of all of these exist that essentially do nothing.
</t>
<t tx="ntallen.20070817133522.5">DG needs a command channel to support:
    Telemetry Start
    Quit
Some DGs could probably get by without any commands (rdr could auto-start end on EOF) but collection definitely needs to receive commands. That means I probably need to support select() on the command server.

Options:
    autostart: Don't wait for 'Telemetry Start' command
    regulate: Request rows based on time regulation (and possibly support speed commands)
    collect: Fill in MFCtr and Synch before calling TM_DG_Get_Data
</t>
<t tx="ntallen.20070820135203">The basic loop will require waiting for:
    Timing pulse
    Incoming commands: use ionotify() to have these send a pulse as well
When the Timing pulse comes in, a row of data is collected and written to TMbfr.
The library could provide a template and fill in the MFCtr and Synch

Could in fact have the writer and reader in separate threads from ctrl and
use semaphores to control execution.

First-cut Ctrl thread uses a timer pulse and MsgReceive() to regulate timing.

Second-cut Ctrl thread reads from /dev/huarp/$Experiment/cmd/DG using ionotify()
to get a pulse delivered as well. Same MsgReceive() loop.

Third-cut Ctrl thread is a resource manager /dev/huarp/$Experiment/DG/$vargroup
to support input from other processes.
</t>
<t tx="ntallen.20070820135203.1">Timing

rdr:
    Get the entire frame from the file, then need to perform sanity checks
inetin:
    Get the entire frame in stream format or QNX4 format, then perform sanity checks before forwarding
</t>
<t tx="ntallen.20070822162630">Can operate full throttle (extraction) or time-regulated (playback)

service_row_timer() {
  transmit_data( single_row );
  fill_buffer()
}

Start a separate thread
full_throttle() {
  while ( started ) {
    fill_buffer();
    transmit_data( 0 );
  }
}
  </t>
<t tx="ntallen.20070822162630.1">Generally operates with local time regulation to absorb any network delays. Incoming data would be placed in a circular buffer and then shipped off to the TMbfr according to the appropriate timing.</t>
<t tx="ntallen.20070823131008">Review the overall architecture again

DG could be implemented as a single thread with an appropriately designed event loop. However, this requires all external I/O to be recast in terms of non-blocking calls with select/ionotify signalling. Some of this can be simplified by breaking into separate threads, but it's worth considering the cost/benefit.

Collection might be a case where three threads is overkill. Two may be plenty, and one may actually be enough. Perhaps going to more threads should be an option, not a requirement.

Collection as single thread:
    on timer pulse, collect the row and transmit it to TMbfr
Collection as three threads:
    on timer pulse, post to semaphore
    writer thread awakes and collects the row, then posts to reader thread
    reader thread awakes and writes to TMbfr

Multi-threaded approaches might be helpful in non-collection cases:
    rdr/extraction: having a separate thread to read and forward data leaves the control thread free to accept commands and gracefully exit.
    rdr/playback: During regulated playback, having the DQwriter as a separate thread and queuing can guarantee smooth operation. During fast forward, DQreader is apt to block on TMbfr, so it should be in a separate thread.
    Inetin/Serin: Three thread design gives most flexibility

I think I need to rethink the core of the data_queue and make these various incarnations sub classes.
------------------------------------------
Probably very similar to TMbfr, except with only one writer and one reader. This simplifies certain things. We don't have to keep track of how many clients have processed a given row.

I have divided the functionality into writer and reader in order to avoid blocking except under controlled circumstances. Writing data to TMbfr is a potentially time-consuming operation. Collection will certainly use the O_NONBLOCK option, but even so, it would be preferable if collection operations were not held up for all the processing required on the TMbfr end. If we put the DG writer and reader functions in separate threads, the reader thread can tolerate the delay while the writer thread continues to process collection operations.

May actually make more sense to break into three threads: Control, assemble and transmit.

DataQueue will be accessed by three threads: control, writer/assembler and reader/transmitter. DataQueue regulates the flow of data through the DG and also supports timing functions. Access to the DataQueue internals is regulated by a mutex.</t>
<t tx="ntallen.20070823131008.1">The DG Writer is the place where all customization takes place. Each DG should create a subclass of DataQueue, overriding a handful of functions including:
    Collect_Rows()
A single object of the subclass should be instantiated and initialized, and then the control_thread() should be invoked. The initialization must define the global tm_info (so the reader thread can properly initialize the connection to TMbfr. It should also define wr_rows_requested, which will be a constant throughout the operation.

    It might be argued that there are cases where the initialization of tm_info might be delayed (Inetin, for example) but I think we're better off discounting that option.</t>
<t tx="ntallen.20070823131008.2">Returns when the space and time is right to collect or transmit more data. For collection, will block on a semaphore waiting for a timing pulse, then verify that space is available in the queue. For other DGs, will block on the queue semaphore.

This routine may block pending forwarding data to TMbfr or a collection timer.
optionally die or do something else that is drastic in the collection case</t>
<t tx="ntallen.20070823131008.3">This is always a non-blocking operation, since the space is already allocated. It may very well kick the reader thread into operation.

Certify rows that have already been written into allocated rows of the DQ. Will perform basic sanity checks. In the case of optimized output formats (T2,T3), will automatically identify the need for new DQD headers (i.e. for missing rows). Note that this function cannot provide missing time stamps; the writer must handle that.

Note that for collection, we will never require a new DQD header except when the timestamp changes</t>
<t tx="ntallen.20070823131008.4"></t>
<t tx="ntallen.20070823131008.5"></t>
<t tx="ntallen.20070823131008.6">Who calls this function? What determines the value n_rows?

n_rows specifies the number of rows to transmit. Actual rows transmitted will be the minimum of:
    n_rows
    rows available in DQD if not the current DQD
timestamps will be transmitted as necessary

Operation may block on a semaphore waiting for or optionally register a pulse to be sent when data becomes available.
    blocking is appropriate for:
        collection
        rdr/extraction w/o any commanding
    pulses are appropriate for non-collection DGs where either commandability or timing is required:
        rdr/playback
        inetin

Need to determine when to unblock/send pulse. Probably when the minimum request requirement is filled.
</t>
<t tx="ntallen.20071127160602">Need to reinstall the development system on desktop
First, make sure everything important is backed up somewhere. Most of the software is already in CVS, so it's just a matter of checking in, but check other directories. Then do the install from CD.

Currently running 6.3.2 Neutrino Host.</t>
<t tx="ntallen.20071127160602.1">/home/nort/work/opt saved to bottesini:QNX6/opt.tar.gz

bsp-x86-bios-1.0.0-20060551018-qnx6.sh: probably not needed
ide-4.0.1-20070810000-nto.sh: probably not needed
ml403_81_1.0.0_project.zip
</t>
<t tx="ntallen.20071204104659">Installing 6.3.2 from CD using my new perpetual license (Email 11/27/2007, Printed and filed)
Installed ssh from the 6.3.1 repository
Installed:
    pkgsrc_qnxutil-0.13.tar.gz (I think)
    bootstrap-pkgsrc-QNX-6.3.2-x86-20071009.tar.gz
Updated configuration as per the wiki doc:
    Added /usr/pkg/bin:/usr/pkg/sbin to PATH
    Added /usr/pkg/lib to CS_LIBPATH via setconf in /etc/rc.d/rc.local
    Set default compiler via: qcc -V 3.3.5,gcc_ntox86 -set-default
        (use qcc -V to see the current default)
Checked out pkgsrc/HEAD
Built:
    autoconf
    automake
    m4
    bzip2
    perl5.8.8
    libtool
    gtexinfo
    sudo (non-pkgsrc)
    nortutil
    nortlib
    cmdgen
    tmlib
    tmphlib
    oui
Still Want/need:
    man: can I port from OpenBSD? Linux?
    
</t>
<t tx="ntallen.20080516115802">Needs to use tm_dev_name() to set up name
Needs to provide time stamping, but perhaps not in playback mode?
Can memo use the msg() library?
Add additional functionality shown below:

Need appropriate library support to tie into nl_error
msg() drop-in replacement for nl_error. Uses msg_hdr prefix, adds severity info
Needs to assemble the entire message into a buffer before sending to memo

I think the time-stamping should take place in the msg() library function. That way if the output is redirected, it retains timestamp info. memo should add timestamp if one is not present

Format of messages to memo should be standardized to allow it to interpret the results and/or filter output
Messages that do not fit the format should be augmented

(\d{2}:\d{2}:\d{2}\s+)?(\[(?:WARNING|ERROR|FATAL|INTERNAL|DEBUG \d+)\]\s+)?(?:(\w+):\s+)?(.*)$
timestamp
severity
application mnemonic
message

Continuation lines are possible, but they must start with a leading space. Memo could insert those as necessary.

msg_hdr set via msghdr_default, -h options
msg( lvl, "my message %d", args )
library adds level message, timestamp:
    00:00:00 [Severity] Hdr: my message 7

time stamps should use UTC.
</t>
<t tx="ntallen.20080516115802.1">Needs cleanup.
Needs to use tm_dev_name() during initialization.
Probably needs proper oui set for consistency.
I think the termination strategy is sound.
</t>
<t tx="ntallen.20080516131227">DG modes:
    
Writer (DG) can specify O_NONBLOCK to signal realtime (i.e. Collection). The significance of O_NONBLOCK is that rows in the TMbfr will be discarded if the clients do not read fast enough. Without O_NONBLOCK, the DG can block waiting for the clients to drain the buffer.

Collection will always specify O_NONBLOCK, except possibly during debugging. Recording the data at the correct rate and logging it is more important than displaying it in realtime. Clients will detect the loss of data and can note it for system tuning.

rdr and Inetin, not being the original collectors, will not usually specify O_NONBLOCK, since they have more leeway with their timing. Again, there may be reason to specify O_NONBLOCK during testing.
</t>
<t tx="ntallen.20080516131227.1">There are two device nodes for reading:
    /dev/huarp/Exp/TM/DCf fast reader interface
    /dev/huarp/Exp/TM/DCo optimal reader interface
    
When reading from the DCf node, a read() operation will return as soon as there is any data ready (although it will return as much data as possible based on the request). disp and algo programs will usually read from DCf.

When reading from DCo, the reader will block until their request is complete. Assuming the request buffer is large, this should involve fewer context switches. This mode is appropriate for lgr or ext programs which have no realtime requirements.</t>
<t tx="ntallen.20080516132543">Reads from one TMbfr and writes to another. Might be the recommended way to run display on another node.</t>
<t tx="ntallen.20080519132626"></t>
<t tx="ntallen.20080623133120">The DataQueue will use two semaphores to help facilitate communication between the threads.

The reader will block on the read_sem, with posts originating either from control or the write thread, depending on the mode of operation.

The writer will block on the write_sem with posts originating either from control (for timing) or the read thread (data flow), depending on the mode of operation.</t>
<t tx="ntallen.20080624104326">
The basic idea for the DG/data/* interfaces is that each is associated with a data set. The driver opens the interface and writes whenever data is ready. Synchronization can be handled in several ways (in subnode)</t>
<t tx="ntallen.20080624104326.1">The basic idea for the DG/data/* interfaces is that each is associated with a data set. The driver opens the interface and writes whenever data is ready. Synchronization can be handled in several ways. Reading from these interfaces is undefined. ionotify and unblock will be supported. Multiple writers are not supported.

Driver interfaces to DG (only during collection) have certain common requirements:
    Define a dataset name
    Define the structure of the data written (struct) for use in the driver and DG
    Provide a stale counter functionality
    Define how the raw data should be mapped into telemetry

Since we are looking at a multi-threaded approach, the raw data area for each interface must be protected by a mutex. As such, access to that data must be controlled. In most cases, all the data from a driver will be reported at the same rate and allocated to TM variables in a block:
    Group driver ( driverStat, driverStale, DetA, DetB, DetC, DetD ) {
      driver.lock();
      driverStale = driver.stale++;
      driverStat = driver.data.status;
      DetA = driver.data.DetA;
      DetB = driver.data.DetB;
      DetC = driver.data.DetC;
      DetD = driver.data.DetD;
      driver.unlock();
      driver.synch();
    }

Sometimes we want to report at different rates or report a single value at a different rate. Would be nice to have get functions:
    DetA = driver.get_DetA;
    DetA = driver.get(driver.data.DetA); or something
It may be possible to automate this via member function templates or something</t>
<t tx="ntallen.20080624104326.2">Want to define a driver super class that encapsulates the usual stuff:
    Method for receiving data
    Method for synchronization
    Method for initialization (call library to set up the mountpoint, etc.)

This can be sub-classed with the specific data structures to be passed</t>
<t tx="ntallen.20080624104326.3">Options for driver synchronization</t>
<t tx="ntallen.20080624104326.4">Data from the write is immediately made available to collection, but the writer is blocked until an appropriate synchronization point (after the data is read into the TM frame, for example)</t>
<t tx="ntallen.20080624104326.5">If O_NONBLOCK is specified, the writer unblocks immediately. ionotify/select requests are honored, and will fire at the same synchronization point.
</t>
<t tx="ntallen.20080625152707">All DGs will use the resource manager interface to adopt
/dev/huarp/$Experiment/DG/cmd
More than one writer is fine. Reading from this interface is not defined.
I don't see any reason to support ionotify or iounblock on this interface, as we will
not enqueue requests.

In addition, the DGs will attempt to read from /dev/huarp/$Experiment/cmd/DG if it exists.
Data read from /dev/huarp/$Experiment/cmd/DG or written to
/dev/huarp/$Experiment/DG/cmd are treated identically.
###Collection probably cannot read from /dev/huarp/$Experiment/cmd/DG because cmd may likely be sending to collection, so there is a risk of deadlock. Probably should dispense with that approach for the DG.

Use message_connect(dpp) to create a connection to the device's channel.</t>
<t tx="ntallen.20080625171218">One per process:
    dispatch_t *dpp = dispatch_create(); // dispatch handle
    dispatch_context_t or thread pool
    control loop
One per thread:
    dispatch_context_t* ctp = dispatch_context_alloc(dpp);
One per device or per device-type or per process, it depends:
    resmgr_connect_funcs_t connect_funcs;
    resmgr_io_funcs_t io_funcs;
One per device:
    resmgr_attr_t
    iofunc_attr_t attr;
One per open:
    iofunc_ocb_t ocb;
    
To support notify, it is necessary to expand IOFUNC_ATTR_T to include an iofunc_notify_t notify[3] element.

I think I should:
    Create a dispatch object that handles dpp and ctp
    Create a device base class to handle resmgr_attach/detach and quit processing
    Create a cmd module that handles all the command stuff
    Create a data module to handle all the driver interface stuff</t>
<t tx="ntallen.20080626163820">resmgr_attach requires a dispatch_t, so we need to instantiate the dispatch object before the devices
each device family will provide its own io_funcs and connect_funcs, but only one per family
each device that is instantiated will have an iofunc_attr_t, unique name, and call resmgr_attach()
  may want to customize nparts_max and msg_max_size</t>
<t tx="ntallen.20080627131220"></t>
<t tx="ntallen.20080627131220.1">QNX Foundation Classes--on Foundry 27
  looks to be an exhaustive C++ framework. As such, it may not be that helpful
  documentation is sketchy: mostly auto-generated using doxygen</t>
<t tx="ntallen.20080627131220.2">Subversion and also Eclipse plugin installation don't work under Neutrino due to current lack of SSL support in the JVM.
Plugins can reportedly be downloaded manually and dumped into the installation hierarchy
</t>
<t tx="ntallen.20080627131220.3">Documentation system. May be worth looking into, but may be a royal pain to build because of all the dependencies.
Then again, it's a cygwin package, so could try it out there...</t>
<t tx="ntallen.20080627131220.4">Framework for packaging and building portable source code across multiple operating systems. From NetBSD.
I used it to build a lot of tools after latest install (see Install above)</t>
<t tx="ntallen.20080630113952">This class encapsulates the main dispatch functionality at the heart of the resource manager framework. It allocates a dispatch handle via dispatch_create() and also is responsible for the main event loop. As such, it either allocates a dispatch context (the current implementation) or sets up the thread pool for a multi-threaded resource.

Any module or object that needs to be part of the main event loop (and ultimately that means any useful part of the program!) needs to hook into the dispatch handle using message_attach(), pulse_attach(), resmgr_attach() or select_attach(). In order to have an orderly shutdown, these objects also need to hook into the quit processing.

A DG_dispatch_client will provide this functionality. When the application is ready to quit (end of input, quit request received, etc.) a quit request is sent to the DG_dispatch object. It will pass the request on to each of its clients until it has no more clients, at which point, it will break out of the event loop and terminate.</t>
<t tx="ntallen.20080702140151"></t>
<t tx="ntallen.20080707135523">Standard oui processing, including initialization hooks
Initialize the interfaces
  needs some sort of hook for adding driver interfaces
Initialize connection to TMbfr
Initialize read and write semaphores
Initialize the read and write threads
main loop {
  monitor:
      timing pulses:
          calls dg-&gt;service_row_timer();
          playback: if (time-blocked) post to read_sem
      incoming commands:
          telemetry start:
              collection or playback: start timing
              extraction (or fast forward): Set mode and post to read_sem
}
</t>
<t tx="ntallen.20080707135523.1">The Read thread reads from the DataQueue and writes to TMbfr
The reader can either be time-blocked or data-blocked. In collection, the reader is always data-blocked, since the writer thread handles the timing. In all the other flavors of DG, it can be either.

ReaderModes:
    timed: block on read_sem and wait for pulse from timer
    untimed: block on read_sem when no data is available

untimed mode applies during collection, fast-forward, or extraction.
timed applies during playback at any regulated speed.

These modes can loosely be thought of as determining which thread we are waiting for (control or writer), but control can always throw in a post to indicate a change in operating mode. For example, if we're data-blocked and a quit command comes through, control will change the operating mode and post to read_sem to unblock the reader. The reader will see that there is still no data, check the operating mode and close the connection to TMbfr

We need to keep track of the selected_mode and the current_mode. The selected_mode is how we want it to work. The current_mode is how it is working at this moment. This is to address underflow during playback or relay operations. If a timing pulse arrives and there is no data available, we want to suspend timing, switch the current_mode to untimed and block again on read_sem. When data arrives, the write thread will see that we are data blocked, so it will post to the read_sem. The read threading then will resume timing

Actually, the read thread should probably initialize the timing at the beginning of playback. The control thread

On init, opens connection to TMbfr and writes initialization, then blocks on the DataQueue. Even in timed modes, the reader thread should immediately become data-blocked. When the first data arrives, if we are in a timed mode, the reader thread should then enable the timer.

In playback mode, the reader blocks on the read_sem, waiting for a timing pulse that tells it another row should go out. If the pulse arrives and there is another row ready to go, it gets shipped and the thread waits again on read_sem. If the pulse arrives and there is no data ready, the timer should be disabled and the thread switched to data-blocked. When data is available, re-enable the timer and switch back to time-blocked

When the data arrives (DQ commit_rows), if the read thread is data-blocked, post to read_sem.

There should never be multiple posts pending on the read_sem.
In playback mode, it gets timing pulses via the read_sem unless there is no data available
In collect mode, the read_sem is controlled by the writer</t>
<t tx="ntallen.20080708133047">In collection, we begin command-blocked. In other modes, we begin data-blocked</t>
<t tx="ntallen.20080708155309"></t>
<t tx="ntallen.20080708155309.1">   This structure type can be used when entire minor frames are
   being transmitted. This is true iff nrows is a multiple
   of nrowminf and the first row transmitted is the first row
   (row 0) of the minor frame. MFCtr and Synch can be extracted
   from the data that follows. data consists of n_rows * nbrow
   bytes.
   
   TMbfr will only output TMTYPE_DATA_T1 records when
   nrowminf == 1.

Applies whenever T3 or T2 do not, i.e. whenever nrowminf==1 &amp;&amp; ( mfc_lsb!=0 or mfc_msb!=1)</t>
<t tx="ntallen.20080708155309.2">   This structure type can be used to transmit rows even
   when the whole minor frame is not present since the
   mfctr and rownum of the first row are included in
   the header. Subsequent rows are guaranteed to be
   consecutive. data consists of n_rows * nbrow bytes.
   
   For practical implementation reasons, TMTYPE_DATA_T2
   will be legal only when nrowminf &gt; 1.

Applies whenever nrowminf &gt; 1
</t>
<t tx="ntallen.20080708155309.3">   This structure type can be used only in the case where
   nrowminf=1, mfc_lsb=0 and mfc_msb=1. data is compressed
   by stripping off the leading mfctr and trailing synch
   from each minor frame. Hence data consists of
   n_rows * (nbrow-4) bytes. All rows are guaranteed to
   be sequential (since there is no way to determine
   their sequence without the mfctr).

Applies whenever nrowminf=1, mfc_lsb=0 and mfc_msb=1</t>
<t tx="ntallen.20080708155309.4">   This structure type can be used under the same conditions
   as tm_data_t3_t. The difference is the inclusion of a
   cksum dword which can be used to verify the data.
   The algorithm for calculating the cksum has yet to be
   defined.
   
The T3 format lacks the synch word and MFCtr that otherwise provide a sanity check on validity of the frame. The T4 format provides a more robust validity check at a lower storage cost.
</t>
<t tx="ntallen.20080708165645">The rest of the siblings of this node are concerned with performing arbitrary translations from one tm_type to another. Most of the complexity can be eliminated by requiring that data generators always use the "right" output format. That of course pushes the complexity into e.g. a legacy rdr app, but that's probably where it belongs.</t>
<t tx="ntallen.20080708165645.1">My initial reaction is "no". The writer threads will need to be aware of the output_tm_type when they fill in the structures. The writer threads will need to do the work if necessary.</t>
<t tx="ntallen.20080709115758">
Somewhere the DG needs to define the data frame (tm_info stuff) to determine the output format.
The DG is required to produce output in the "correct" format:
    
    if (nrowminf &gt; 2) output = T2
    else if ( mfc_lsb==0 &amp;&amp; mfc_msb==1 ) output = T3
    else output = T1

Wherever input is coming from, it is the DG writer's job to make sure the output is in the correct format. This should only be an issue for legacy rdr implementations and/or QNX4 Inetin.</t>
<t tx="ntallen.20080710162929">class data_queue { // base class:
    Supports event/dispatch loop
    attaches tm_dev_name("DG/cmd");
    reads from tm_dev_name("cmd/DG");
    provides timer functionality for regulated output {
      default functionality:
      regulated: transmit one row per timer pulse
    }
    provides data queue with writer and reader functions
    provides regulated and unregulated output to TMbfr {
      transmit_data( int single_row )
      if single_row is non-zero, one row will be sent if there
      is any data in the queue. If single_row is zero, then all
      the data available in the queue will be sent. If any limits
      are set (advance to time) they are checked and may stop
      telemetry.
    }
    subclasses are charged with filling the queue
}
class collection : public data_queue {
    operation is always regulated
    time base is invariant
    communication with TMbfr is non-blocking
    output to TMbfr should be essentially unregulated {
      by which I mean the output stage should output whatever
      is in the queue. The regulation is on the input side
      of the queue.
    }
    on each timer pulse {
      get_data (collect a row)
      flush DQ to TMbfr
    }
}

class extraction : public data_queue {
    three thread implementation
    output may be regulated
    time base may be variable
    communication with TMbfr can block
    service_timer() {
   }
    create a data thread {
      unregulated operation: create a separate thread to loop:
        check for commands
        get data
        flush DQ to TMbfr
      regulated operation: create a separate thread with a semaphore
        on each timer pulse, sem_post
        On each semaphore:
            check for commands
            transmit one row
            if below low water mark, get data
      Communication from control to subthread can be synchronized via the semaphore
      Communication from subthreads to control will require a pulse (see DG_tmr)
      This is specifically required in the case of subthread termination (e.g. EOF)
      Could piggyback on the timer pulse (or not)
    }
}
</t>
<t tx="ntallen.20080710162929.1">To begin with, the control options:
    regulation_optional boolean
    rate_adjustable boolean (probably assume true if regulation_optional)
    regulated  boolean
    row_rate   rows per second
TM start:
    Set start condition
    If regulated, program timer
    else stop timer
    if ext_stop, signal handlers
TM end/stop
    Set stop condition
    stop timer
    if ext_time, signal handlers
Quit
    Set stop and quit conditions
    stop timer
    if ext_stop or ext_time, signal handlers
TM play
    if regulation_optional
      set regulated
      set row_rate to default
      if stopped, do start
      else reprogram timer
TM fast forward
    if regulation_optional
      stop timer
      set unregulated
      if stopped, do start
      else if ext_time, signal handlers
TM faster
    if regulation_optional
      if stopped
        do play
      else if regulated
        increase row_rate
        program timer
</t>
<t tx="ntallen.20080710162929.2">Not necessarily a separate thread: override service_timer() {
  get_data(); // Collect one row
  transmit_data(0);
}
</t>
<t tx="ntallen.20080710162929.3">extraction_thread() {
  for (;;) {
    lock();
    if ( quit ) {
      unlock();
      break;
    }
    if ( ! started ) {
      ot_stopped = true; // Is this necessary?
      unlock();
      sem_wait(&amp;ot_sem);
    } else {
      ot_stopped = false;
    if ( regulated ) {
      // timed loop
      ot_stopped = false;
      for (;;) {
        ot_time_blocked = 1;
        unlock();
        sem_wait(&amp;ot_sem);
        lock();
        int breakout = !started || !regulated;
        unlock();
        if (breakout) break;
        transmit_data(1); // only one row
        if (low on data) get_data();
        lock();
      }
    } else {
      // untimed loop
      for (;;) {
        int breakout = !started || regulated;
        unlock();
        if (breakout) break;
        get_data();
        transmit_data(0); // everything. Include checks for time limits?
        lock();
      }
    }
  }
  signal parent thread that we are quitting
}
</t>
<t tx="ntallen.20080715165457">Always define ROLLOVER (check the definition!)
Always define INVSYNCH (as 0 or 1) (made)
Figure out how to handle home row definition for T3 encoding
  simplest strategy is probably to adjust the pointer to point two chars ahead of the row
  need to guarantee that MFCtr and Synch are actually not written.
  Alternately, could reformulate place_home to start at offset 2
  
  place.c if TM_Output_Type == 3, start at offset 2.
  
  Should consider elminating definition of Synch in the home_row. Although we won't reference it, it is wrong.

Always generate collector::tminitfunc();
</t>
<t tx="ntallen.20080716155154">Base class for DGs and DCs. TMbfr uses a more complicated queueing structure
</t>
<t tx="ntallen.20080716155154.1">Derived from data_queue, supports data generators
All DGs:
    attach /dev/huarp/$Experiment/DG/cmd and accept commands written thereto
    open /dev/huarp/$Experiment/TM/DG and write the data stream to it</t>
<t tx="ntallen.20080716155154.2">Derived from data_generator, supports collection.</t>
<t tx="ntallen.20080716155154.3">Derived from data_generator, supports non-collection DGs (rdr, Inetin, etc.)</t>
<t tx="ntallen.20080716155154.4">Derived from data_queue? supports data clients that read from TMbfr.

Needs to read from TMbfr
For running with Photon:
    phtable produces #include "tablelib.h"
    We can test below via #ifdef TABLELIB_H
    Need a different control loop if running with Photon. Actually just tap into Photon's
    Also need to call phinitfunc(): That really needs to be generated by tmc ala tminitfunc()
        It just needs to call PtInit() and each of the &lt;table&gt;_init() functions
Otherwise
    Simply read from TMbfr until we have a block big enough to write into the queue, then
    write it. Is there any advantage in using the data_queue at all in this case? TMbfr will
    have determined the proper placement of timestamps, etc. Of course it's possible we
    might have missed some data, so local handling of that might be a good idea. What
    else could a local data_queue do for us?
    
    lgr could benefit from a local data_queue, because it does some repackaging, so it
    would like to accumulate rows until it has enough to write to disk. The data_queue
    would help determine exactly when a new dqd is required, and hence when a new header
    is required in the output file.
    
    However, in a generic client, you cannot instantiate the data_queue until your know
    the frame dimensions</t>
<t tx="ntallen.20080716230618">Existing algorithm does not do the right thing in certain odd cases.
If the data rate is n/d mf/sec and there are M minor frames per major frame
and n does not divide M, we could run into trouble.
If we choose our rollover point R to be a multiple of both M and n, that
will also work. That would be a multiple of lcm(M,n), ideally the
largest multiple less than 2^16. R = a*lcm(M,n) &lt; 2^16 so choose
a = floor(2^16/lcm(M,n)) or
R = floor(2^16/lcm(M,n))*lcm(M,n)
Then R is a multiple of M and n, and Rd = a*n*d
which is a multiple of n and hence an even number of seconds.

Since we have traditional stuck to powers of 2 (4 Hz, 8 Hz, etc.)
this hasn't been an issue.

In the truly rare case that lcm(M,n) &gt;&gt; M or n, we could gain more
flexibility by not insisting that the timestamp reference MFCtr value
start at zero. This approach is:

    Normal implicit timestamp update without wrapping. In this case,
    we don't want to change m (the current MFCtr), we just want to
    update the timestamp, (t1,m1), such that the calculated time
    does not change over the transition. Hence
      t = (m-m0)*d/n + t0 = (m-m1)*d/n + t1
      nt = d(m-m0) +n*t0 = d(m-m1) + n*t1
      d(m1-m0) = n(t1-t0)
    Since n divides the right hand side, it also divides the left
    hand side, and since n and d are relatively prime, n|(m1-m0).
    Hence if n|m0, then n|m1:
         q = floor((m-m0)/n)
        m1 = m0+q*n
        t1 = d*(m1-m0)/n = d*q
    
    Normal implicit timestamp with wrapping: Same conditions apply,
    but now we are in fact modifying m to m*. Need to preserve Major
    frame phase [ m%M = m*%M] as well as time phase [(m-m0)%n = (m*-m1)%n]
    
    Suppose we choose to always wrap at 2^16:

    Simple approach is to choose m* = (2^16)%lcm(M,n). This will preserve
    both phases. Under this approach, the timestamp MFCtr references will
    always be divisible by n, and we can easily reset m1 = 0 on wrap:
        m* = (2^16)%lcm(M,n)
        m1 = 0
        t1 = t0 + d(2^16 - m* - m0)/n

    In the truly rare case where lcm(M,n) is much larger than M or n (where
    M and n are both large and relatively prime) are more complex approach
    may be desirable that does not require the MFCtr references to be
    divisible by n. I will not bother to implement this scheme.
    choose m** = 2^16%M. This satisfies the first condition.
    Now dm = (2^16 - m0)%n. This is our time phase. If dm &lt;= m**, we can choose
    m1 = m*-dm, otherwise we need to increase m* by multiples of M until it is
    &gt;= dm
    
    Need m**+a*M &gt;= dm  hence a*M &gt;= dm-m** so
    
    if ( dm &lt;= m**) {
      a = floor((dm-m**)/M)
      m* = m**+a*M (new next_minor_frame)
    } else m* = m**
    m1 = m*-dm (new timestamp reference)
    t1 = t0 + d*(2^16-m* + m1 - m0)/n
    </t>
<t tx="ntallen.20080720213239">Simply read from TMbfr into a large buffer and operate on what arrives

Provide a largish buffer
Function to read into the buffer and dispatch service functions when complete records are received
Different event loops can

basic_read() {
  read(bfr_fd)
  if complete, call appropriate processing function
  if leftover, move it to the front of the buffer
}

basic_loop() {
  while (!quit) {
    basic_read();
  }
}

It isn't clear to me whether a triggered read needs to read until nothing is available or what.
If we were using ionotify directly, we would call ionotify after the read and it would tell us
if there was more data ready. I guess that must be how they do it. In that case, we can do
a single read and be done.
triggered_read() {
  basic_read();
}
</t>
<t tx="ntallen.20080720213239.1">Ties into Photon's event loop. Uses ionotify to get pulses signaling data ready from TMbfr.
After that, very similar to the basic client

</t>
<t tx="ntallen.20080720213239.2">Use ionotify to read from both TMbfr and command server (lgr?)
Since the lgr has much more complicated data processing, it will probably
require it's own stuff.
</t>
<t tx="ntallen.20080724120806">In current practice under QNX4, we use da_cache (originally implemented to cache write-only values of D/A devices) as a cheap means of communicating data values between applications. Since the cache had established a presence in one locations, neither client needed to go through the hassle of becoming a server. There was a bit of a kluge involved because the addressing was arbitrary and was a little tricky to communicate between the clients.

The question at hand is how best to serve the needs of cache clients in QNX6.
Cache clients include:
    Command server (for communicating SW status values)
    Device drivers (for communicating status values and possibly retrieving control values)
    Collection (for retrieving status values to be reported)

Because the general nature of the QNX6 architecture discourages the old send/receive/reply approach, it isn't obvious how a similar cache might be implemented, so that begs the question of whether it should be implemented. There are many options:
    A: Use resmgr to establish the name, but use non-standard messaging to implement the old protocol
    B: Use resmgr to establish a single name. Writes would be encoded as before (address, length, data). Reads would deliver the entire address space every time, or could implement seek and use combine messages...
    C: Use resmgr, read a config that associates names with regions of specific sizes. Writes write the entire subregion, Reads read the entire subregion. In addition, could wait for updates and provide signals as necessary.

All of these approaches assume cache is useful and would require not only implementation, but also modifications to the Collector and/or tmc. Also to consider not using cache. For starters, all device drivers would use the standard TM Receive libary, but that leaves open the question of how the Command Server should communicate with Collection:
    D: Command server use TM Receive, but that requires we keep the current architecture where commands to DG are handled differently (via a write to DG) from commands to everyone else (handled as reads from cmd)
    E: Command server uses standard interface for DG and extends it to include data
        Downside is this would require more interpretation on the collection side, plus agreement on the names
    F: Command server uses standard interface for DG, additional (standard) interfaces for data channels. Requires tmc to be modified to recognize a different flavor of TM Receive.

I think the simplest approach is to go with D for now and consider extending to F in the long run.
</t>
<t tx="ntallen.20080724120806.1">Associates a name with a range of data
Create an object name_dev which includes all the info we need for handling interactions
object should be defined statically so modifications can be made during other initializations
create tm_dev_name(DG/data/name) as writable
option to support synchronization. If not, we'll just take writes whenever, return immediately and ionotify will always report ready. If we opt for synchronization, we must also provide an indication of the synch point. Blocking writes will take effect immediately but block until the synch point. Non-blocking writes will take effect immediately, but will not statisfy the ionotify conditions until the next synch point.
</t>
<t tx="ntallen.20080724120806.2">#include "collect.h"
send_id Col_send_init(const char *name, void *data, unsigned short size);
int Col_send(send_id sender);
int Col_send_reset(send_id sender);

For non-blocking synchronization, it's a little trickier.
 Can use select if we're just monitoring fds.
 If we're running an event loop (dispatch, photon) do what is necessary in that case.
 Those libraries provide convenience functions that do most of the work.
</t>
<t tx="ntallen.20080724120806.3"></t>
<t tx="ntallen.20080729145409">subbus: Need to write it
lgr: Need to write it
rdr: Need to write it
  tmpplib: DGext.[ch] (Extractor.[ch]*** Has not been tested. It's a DG interface for rdr, Inetin, etc.
tmphlib/nlphcmd.c: Read from tm_dev_name("cmd/quit");
qcli:
  Remember to ask Marco about use of DAC3 for heater, other configuration issues

TMbfr: Will need further work to support additional data formats

2nd Pass:
    memo: add additional tricks, use msg() library
    tmcalgo: need some form of runtime verbosity (nl_cons stuff)

Done: Move the following into tmpplib:
    DQ.[ch]
    DGcol.[ch]
    DC.[ch]
    DCph.[ch]
    DG.[ch]
    DG_Resmgr.[ch]
    DG_cmd.[ch]
    DC_data.[ch]
    DG_tmr.[ch]
Done: appgen: Port it
Done: sspdrv
Done: DG_data.cc: Add synchronization stuff
Done: memo: oui. provide library hooks into nl_error
</t>
<t tx="ntallen.20080908205900">Three threads encapsulated in DG_rdr class:
    Control thread:
        uses basic DG_col operation
    Input thread:
        uses DC_rdr class to read, then blocks while allocating rows
    Output thread:
        invokes transmit_data()

DG_rdr additional attributes
  These are set by the output thread to indicate what it's waiting for. They should
  be cleared by the thread that is resetting the condition. Only one should be
  set at any time.
    #define OT_BLOCKED_STOPPED 1
    #define OT_BLOCKED_TIME 2
    #define OT_BLOCKED_DATA 3
    int ot_blocked;
    #define IT_BLOCKED_DATA 1
    bool it_data_blocked;
    sem_t ot_sem;
    sem_t it_sem;</t>
<t tx="ntallen.20080909114112">Process command line options:
    autostart/regulated (playback)
    autostart/unregulated (extraction)
        perhaps autostart should just mean autostart/unregulated, since you can interactively start otherwise
    starting time
    ending time

Startup Input and Output threads

Process incoming commands and feedback from I/O threads:
    Main loop is DG_Resmgr dispatch loop, so in order to get anything back from subthreads,
    we'll need to send a pulse.
    
    To use a pulse in this case we will hook into the dispatch loop as a DG_dispatch_client.
    
    Alternately, we could simply open a connection to the command interface and send the quit command.
    
    Telemetry Start

Review functionality in 'Commands' above.

override event()
  switch (evt) {
    case dg_event_start:
      lock();
      if (ot_blocked) {
        ot_blocked = 0;
        post(&amp;output_sem);
      unlock();
      break;
    </t>
<t tx="ntallen.20080909114112.1">Invokes DC's operate loop. Overrides:
    In the operate loop, check for quit.
    
    process_tstamp() {
      invoke commit_tstamp() if it's actually new
    }
    process_data() {
      allocate_rows(); block if zero
      commit_rows();
    }
    process_eof() {
      get the next file.
    }</t>
<t tx="ntallen.20090202133816"></t>
<t tx="ntallen.20090202133816.1">We currently have a hand-crafted doit script for tilde. It is based on the old QNX4 script, and has a certain amount of configurability built in, but it has only been utilized for tilde.</t>
<t tx="ntallen.20090202133816.2">In this configuration, we assume the experiment runs on a dedicated node. This means that the startup is configured to automatically log in as the data acquisition user ('flight'). This user should be configured to run /usr/local/sbin/flight.sh as the login shell (set in /etc/passwd).

When doit runs, we may expect to find the experiment in any one of several states:
    Idle: No sign of parent or cmdsrvr. May actually be powered off.
    Transitional: parent but no cmdsrvr
    Operational: parent and cmdsrvr


The experiment status is determined by the presence of the parent and/or cmdsrvr device interfaces (/dev/huarp/$Experiment/cmd/server). Of course there are many other components of the experiment that could be running, but without the cmdsrvr, we don't have normal basic control, so we'll consider that state 'transitional' or 'damaged'. Usually the only thing we want to do if we find the experiment in the transitional state is to shut it down completely so we can start afresh.

The basic idea of the dedicated node is that parent is essentially always running. In order to start the experiment, it is necessary to terminate the currently running parent so it will be automatically replaced by a new invocation. This is in contrast to the development node model where there is usually no parent running, and we need to start one up in order to start up the experiment.

The basic doit commands are:
    not: shut down a damaged experiment tree or prevent a booting system from starting up a new tree
    start: start up a new experiment tree and client functionality
    stop: execute an orderly shutdown of a running experiment
    wait: start up client functionality only after locating an existing experiment tree

not:
    If instrument is operational, do nothing and complain
    wait for parent
    take action to prevent the instrument from restarting
    signal current parent to quit

start:
    wait for parent
    If instrument is not running:
        take action to start up right
        signal current parent to quit
    wait for cmdsrvr, then start the rest of the client software

stop:
    If instrument is running, send "Quit" to cmdsrvr
    else complain
</t>
<t tx="ntallen.20090202133816.3">In this configuration, we assume the experiment can run on the current node and that there is no login dedicated to data acquisition.

When doit runs, we may expect to find the experiment in any one of several states:
    Idle: No sign of parent or cmdsrvr
    Transitional: parent but no cmdsrvr
    Operational: parent and cmdsrvr

The basic doit commands are:
    not: shut down a transitional tree, otherwise do nothing
    start: start up a new experiment tree and client functionality
    stop: execute an orderly shutdown of a running experiment
    wait: start up client functionality only after locating an existing experiment tree

not:
    If instrument is running, do nothing and complain
    If parent is not running, do nothing and complain
    take action to prevent the instrument from restarting (probably unnecessary)
    signal current parent to quit

start:
    # wait for parent
    switch (state)
      Idle:
          take action to start up right
          start up flight.sh
          start client stuff
      Transitional:
          complain and die
      Operational:
          Just start client stuff

stop:
    If instrument is operational, send "Quit" to cmdsrvr
    else complain
</t>
<t tx="ntallen.20090203160910">I want to start from this prototype to develop a widget or something like a widget to provide a graph that can be included within some other application.

Features:
    One or more data sets (x,y)
    Selectable line styles, markers
    Axis Labels
    Autoscaling, zoom, fixed</t>
<t tx="ntallen.20090203160910.1">plot_obj : polymorphic superclass
    Attributes:
        type  (po_figure, po_axes, po_line, po_poly, po_text, po_zoom, po_max)
        first, last, next: children
    Methods:
        add_child
        plot(x,y)
        virtual plot(y)
        virtual render()
        virtual callback()

figure : public plot_obj
  A figure is a window which may contain one or more axes. Creating a figure currently
  creates a new window. If you already have a window and you want to add axes to it,
  or begin with a non-standard size, you'd have to extend the constructor.
    Attributes:
        window
        size
        current_axes
    Methods:
        figure();
        figaxes() creates default axes
        plot(), render(), callback()

axes : public plot_obj
  axes define the graphing area for the data points. The initial default is for the axes to
  take up the entire figure area, which is the entire window. This definition should be
  refined so that the axes area includes area required by the labels and a graphing
  area should be carved out of that. Axis labels might be sub-objects or might just be
  attributes of the axes.
  
  axes have line children
  
    Attributes:
        fig; parent figure
        area; location of axes within figure
        xscale, yscale
    Methods:
        plot(), callback(), [render()]
        zoom()

line : public plot_obj
  A line actually supports multiple lines as specified by one or two matrix objects (matlab-style).
  As such, it has one or more polyline objects as children.

polyline : public plot_obj
  Polyline object supports a single graphical line, but it may be implemented by patching together
  multiple polyline widgets if necessary.</t>
<t tx="ntallen.20090203160910.2">1. Single XY axis pair. Basic labeling options:
    Draw axis 0
    Draw ticks 0
    Draw tick Labels 0
    Label axis 0
    Reserve tick space 0
    Reserve label space 0
    Axis color
    Tick Label Style
    Axis Label Style
    Tick Length
    Label Length

    This representation allows for left, right, or both positioning of axis labels and ticks.
    In practice, a subset of options would probably apply. For example, I could decide that
    if you are going to draw one axis, you draw both. If you add tick marks, you add them
    to both. Or I could support drawing axis and tick marks together with tick labels or on
    both axes, but not say only on the opposite axis. Decoupling the 'Reserve Space' options
    from the 'Draw' options allows support for overlays

2. Overlaying multiple axes in the same space
    We want the graphing area to end up the same, and perhaps we want either the x or y axes
    to be locked together. In this case, we would want to reserve space for axis tick marks
    and/or labels but not actually draw them.
</t>
<t tx="ntallen.20090203162108">Axes currently fill their parent's area which is currently a figure which corresponds directly to a window widget.
Since any non-trivial application will require additional controls on the window, it makes sense to allow axes to use a subset of the parent's area. Possible approaches include:
    1. axes can be created with their (fixed) outer box specified (i.e. on a TM data display)
    2. axes can be created inside a panel object, which could be resized independently of the window</t>
<t tx="ntallen.20090203162108.1">Current design is missing many dynamic features.
Objects are created and displayed, but never destroyed, erased or redrawn.
What needs to be done in order to redraw</t>
</tnodes>
</leo_file>
